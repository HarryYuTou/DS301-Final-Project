{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2198b5c5c2b345498d4549b18bac8b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d6b29e6e3f04012bd3c2d34e441302d",
              "IPY_MODEL_4e1e9308964941d581057af5a70835f6",
              "IPY_MODEL_991844232f8442e99a14e46dd61d3822"
            ],
            "layout": "IPY_MODEL_b5b3390d391849fb85758cdf72bd9749"
          }
        },
        "3d6b29e6e3f04012bd3c2d34e441302d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5185b24e1234cab8cf91d6b7fa864eb",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d11f4215a847efac00c0045a6e0440",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4e1e9308964941d581057af5a70835f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e867fd16aa8544ea867f1c4aae40bad7",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e0bfb4e06dd4cba8ff041c745eb570e",
            "value": 48
          }
        },
        "991844232f8442e99a14e46dd61d3822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430df64c3d7a44bb84412439846062fb",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f01634a6654572a0673eb8c34f18d3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.50kB/s]"
          }
        },
        "b5b3390d391849fb85758cdf72bd9749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5185b24e1234cab8cf91d6b7fa864eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d11f4215a847efac00c0045a6e0440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e867fd16aa8544ea867f1c4aae40bad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0bfb4e06dd4cba8ff041c745eb570e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "430df64c3d7a44bb84412439846062fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f01634a6654572a0673eb8c34f18d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a02a0644fd5d4e62a4a15645dd3e32c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d10e395050704ec591143500de6eed72",
              "IPY_MODEL_18f47141d158492eb0798beb1db25e5e",
              "IPY_MODEL_dc12e7f1fe63444c9712dbc9bf7a28d1"
            ],
            "layout": "IPY_MODEL_aad5c4fffae041aea58e0be154e594d9"
          }
        },
        "d10e395050704ec591143500de6eed72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d11209b79baf45989d5c33459a546bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_5f096c4390bc4bb790e15831a5cdfefd",
            "value": "vocab.txt: 100%"
          }
        },
        "18f47141d158492eb0798beb1db25e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e84ff9c4274ecfa9f824df16064916",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0544efcf9997453690b65c62d84cb023",
            "value": 231508
          }
        },
        "dc12e7f1fe63444c9712dbc9bf7a28d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afafa8dc8b89492d8de254129be9cf87",
            "placeholder": "​",
            "style": "IPY_MODEL_0fab9d1b45064ae2a295e32b68a836eb",
            "value": " 232k/232k [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "aad5c4fffae041aea58e0be154e594d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11209b79baf45989d5c33459a546bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f096c4390bc4bb790e15831a5cdfefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e84ff9c4274ecfa9f824df16064916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0544efcf9997453690b65c62d84cb023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afafa8dc8b89492d8de254129be9cf87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fab9d1b45064ae2a295e32b68a836eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d39517b1d7540848d78264115b1a2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21070b999987427192adc27b5aef4051",
              "IPY_MODEL_9bdaeed4d96644da923c7f06e989f36e",
              "IPY_MODEL_beb5a63a16454465a494525a6082a2ce"
            ],
            "layout": "IPY_MODEL_2d0adc2892464cef9150fed62169d047"
          }
        },
        "21070b999987427192adc27b5aef4051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b27cd0202044f2282160aeac1994557",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ee243c341f46e2aead8cbafdc968fc",
            "value": "tokenizer.json: 100%"
          }
        },
        "9bdaeed4d96644da923c7f06e989f36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2005ae833d1c469a85da7e3b09467a5b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be5fbae28e944bedb2b129a4369e728f",
            "value": 466062
          }
        },
        "beb5a63a16454465a494525a6082a2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ea697a2b204c33a63daf7c2fb73e06",
            "placeholder": "​",
            "style": "IPY_MODEL_c22f5dd016e94e919b9b4336f08272bf",
            "value": " 466k/466k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "2d0adc2892464cef9150fed62169d047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b27cd0202044f2282160aeac1994557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ee243c341f46e2aead8cbafdc968fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2005ae833d1c469a85da7e3b09467a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5fbae28e944bedb2b129a4369e728f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47ea697a2b204c33a63daf7c2fb73e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22f5dd016e94e919b9b4336f08272bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3660602b41b643e49e1266023f5aad24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e76fedd66a1741de82f9fe64a6640e3d",
              "IPY_MODEL_5335c3cf3f4441ca81d3f907d279298f",
              "IPY_MODEL_454e8dd3bf10407280091c02797229fe"
            ],
            "layout": "IPY_MODEL_4771ec0dfd524bfda065279e781706f0"
          }
        },
        "e76fedd66a1741de82f9fe64a6640e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b8f9626ebe4ff3b63cf8797daeb1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1d568aaccc452689704a4e13886098",
            "value": "config.json: 100%"
          }
        },
        "5335c3cf3f4441ca81d3f907d279298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71f75cb0cbc49c1b11525575d0ff78c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f730a4ab6fda4f6a84715aed8421d8fa",
            "value": 570
          }
        },
        "454e8dd3bf10407280091c02797229fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d65ac8a65c44578af6ea7a57c57c4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_b498a3d77c874371a52d4de963b696ca",
            "value": " 570/570 [00:00&lt;00:00, 71.4kB/s]"
          }
        },
        "4771ec0dfd524bfda065279e781706f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b8f9626ebe4ff3b63cf8797daeb1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1d568aaccc452689704a4e13886098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c71f75cb0cbc49c1b11525575d0ff78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f730a4ab6fda4f6a84715aed8421d8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d65ac8a65c44578af6ea7a57c57c4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b498a3d77c874371a52d4de963b696ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8ed47464c240fdba27ccd349abd97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73c75c6a907f4b2b8cdbbd78d17d9fae",
              "IPY_MODEL_e6eb5222dbef44bd93680b7d2dc6b701",
              "IPY_MODEL_76502d0b99104bdda2ae56d45d4156d5"
            ],
            "layout": "IPY_MODEL_5ff9044a46de444ea4e87d59d6912675"
          }
        },
        "73c75c6a907f4b2b8cdbbd78d17d9fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09792d75690b43e2989bc566ffcc63c6",
            "placeholder": "​",
            "style": "IPY_MODEL_57460589b92348e9b49a619d8ad78a0f",
            "value": "model.safetensors: 100%"
          }
        },
        "e6eb5222dbef44bd93680b7d2dc6b701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed70816e1984d28b98127bff989d909",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5187192347604c5e8ed5bc4f41866921",
            "value": 440449768
          }
        },
        "76502d0b99104bdda2ae56d45d4156d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a651ad894e548978f186fd2a009a226",
            "placeholder": "​",
            "style": "IPY_MODEL_93b0ca00a61c412899dd9f573fbaa6db",
            "value": " 440M/440M [00:00&lt;00:00, 524MB/s]"
          }
        },
        "5ff9044a46de444ea4e87d59d6912675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09792d75690b43e2989bc566ffcc63c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57460589b92348e9b49a619d8ad78a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ed70816e1984d28b98127bff989d909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5187192347604c5e8ed5bc4f41866921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a651ad894e548978f186fd2a009a226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b0ca00a61c412899dd9f573fbaa6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load dataset"
      ],
      "metadata": {
        "id": "-jMAYfaTUrQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pdmSOZ1ncVV",
        "outputId": "1bc762d6-cc85-4742-b890-9f11d44ccf7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/MMHS150K.zip -d /content/MMHS150k/"
      ],
      "metadata": {
        "id": "ycKK-V7_nyA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"/content/MMHS150k\"\n",
        "print(os.listdir(base_dir))"
      ],
      "metadata": {
        "id": "Ids77QQPyEgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ff7a32-b6a0-4668-ae13-725a7d54b0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MMHS150K_GT.json', 'splits', 'img_txt', 'MMHS150K_readme.txt', 'hatespeech_keywords.txt', 'img_resized']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed=2025"
      ],
      "metadata": {
        "id": "DB12WA9vRbOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model: Pure text using LSTM"
      ],
      "metadata": {
        "id": "xeATZcPtPJHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting text data"
      ],
      "metadata": {
        "id": "P-K_HWEQPn4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load JSON annotations\n",
        "with open(\"/content/MMHS150k/MMHS150K_GT.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract tweet_text and labels\n",
        "# Convert to DataFrame\n",
        "text = []\n",
        "for image_id, content in data.items():\n",
        "    text.append({\n",
        "        \"texts\": content[\"tweet_text\"],\n",
        "        \"label\": content[\"labels\"]\n",
        "    })\n",
        "\n",
        "text_df = pd.DataFrame(text)\n",
        "print(text_df.head())\n",
        "print(text_df['label'].value_counts())  # see class distribution"
      ],
      "metadata": {
        "id": "tPGkuQ_SHT1p",
        "outputId": "4dd949ee-66bb-41d7-cefa-7064b2983430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texts      label\n",
            "0       @FriskDontMiss Nigga https://t.co/cAsaLWEpue  [4, 1, 3]\n",
            "1     My horses are retarded https://t.co/HYhqc6d5WN  [5, 5, 5]\n",
            "2  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...  [0, 0, 0]\n",
            "3  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...  [1, 0, 0]\n",
            "4  “EVERYbody calling you Nigger now!” https://t....  [1, 0, 1]\n",
            "label\n",
            "[0, 0, 0]          57890\n",
            "[0, 1, 0]          10285\n",
            "[0, 0, 1]          10246\n",
            "[1, 0, 0]           9793\n",
            "[0, 5, 0]           3606\n",
            "                   ...  \n",
            "[1, 3]                 1\n",
            "[5, 0, 0, 0, 0]        1\n",
            "[0, 0, 0, 1]           1\n",
            "[1, 0, 0, 1]           1\n",
            "[2, 0]                 1\n",
            "Name: count, Length: 232, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the text data"
      ],
      "metadata": {
        "id": "_4wIg1JdP3Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", '', text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", '', text)            # Remove mentions\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", '', text)     # Remove special characters\n",
        "    return text.lower().strip()\n",
        "\n",
        "text_df['clean_text'] = text_df['texts'].apply(clean_text)"
      ],
      "metadata": {
        "id": "Kp-kbKpjP63j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(text_df['clean_text'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(text_df['clean_text'])\n",
        "X = pad_sequences(sequences, maxlen=100, padding='post')  # shape: (n_samples, 100)"
      ],
      "metadata": {
        "id": "0CB8iKUBQBfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf5WfnwMQVt2",
        "outputId": "5c9b1ffa-6d34-43cd-d769-713baf12ccb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,    0,    0, ...,    0,    0,    0],\n",
              "       [   9, 2297,   54, ...,    0,    0,    0],\n",
              "       [   2,   16,  312, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   9,    2,   94, ...,    0,    0,    0],\n",
              "       [ 124,   75,   26, ...,    0,    0,    0],\n",
              "       [   5,    2, 1364, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def multi_hot_encode(label_list, num_classes=6):\n",
        "    vec = np.zeros(num_classes)\n",
        "    for label in label_list:\n",
        "        vec[label] = 1\n",
        "    return vec\n",
        "\n",
        "Y = np.array([multi_hot_encode(label) for label in text_df['label']])"
      ],
      "metadata": {
        "id": "mk9SzImIQYPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAGbk4aPQaHx",
        "outputId": "68cce9f4-1d25-4a6f-edc1-2034581ca2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 1., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 1., 0., 0., 0., 0.],\n",
              "       [1., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test valid split"
      ],
      "metadata": {
        "id": "RSZsW3CHQnIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: train vs temp (val + test)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Second split: temp into validation and test (50/50 of the 20%)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Validation shape:\", X_val.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of0M84CeQsT9",
        "outputId": "d3f6455e-a364-44c9-c28f-1ac46f5392e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (119858, 100)\n",
            "Validation shape: (14982, 100)\n",
            "Test shape: (14983, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the LSTM Model"
      ],
      "metadata": {
        "id": "sUdrLh5hQ9uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model_base = Sequential([\n",
        "    Embedding(input_dim=20000, output_dim=128, input_length=100),  # input: word indices\n",
        "    LSTM(128, return_sequences=False),  # LSTM layer with 128 units\n",
        "    Dropout(0.5),           # Prevent overfitting\n",
        "    Dense(64, activation='relu'),      # Fully connected layer\n",
        "    Dense(6, activation='sigmoid')     # Output layer for 6 labels, sigmoid for multi-label\n",
        "])\n",
        "\n",
        "model_base.compile(\n",
        "    loss='binary_crossentropy',  # For multi-label classification\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOJDtzn1RA4E",
        "outputId": "a56de929-835b-4457-ea35-da18b8fd3093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "gX5b_VJdRD22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_base.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, Y_val)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T8qryCVRN_u",
        "outputId": "2f4c9db3-c6f7-44d0-b849-13eea519a222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9389 - loss: 0.3552 - val_accuracy: 0.9427 - val_loss: 0.3412\n",
            "Epoch 2/5\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9424 - loss: 0.3434 - val_accuracy: 0.9427 - val_loss: 0.3411\n",
            "Epoch 3/5\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9420 - loss: 0.3431 - val_accuracy: 0.9427 - val_loss: 0.3418\n",
            "Epoch 4/5\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.3419 - val_accuracy: 0.9427 - val_loss: 0.3411\n",
            "Epoch 5/5\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.3427 - val_accuracy: 0.9427 - val_loss: 0.3410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e3204767010>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "POnoRwsIRYOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted probabilities on the test set\n",
        "y_probs = model_base.predict(X_test)\n",
        "\n",
        "# Binarize at threshold 0.5\n",
        "y_pred = (y_probs >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "yycJx4O-RWng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcee9c8-7da5-403f-9b05-c90f2d832eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score, average_precision_score\n",
        "import numpy as np\n",
        "\n",
        "# Class names as string\n",
        "target_names = [str(i) for i in range(6)]\n",
        "\n",
        "# Print detailed per-class report\n",
        "print(classification_report(Y_test, y_pred, target_names=target_names, zero_division=0))\n",
        "\n",
        "# Global scores\n",
        "print(\"F1 Micro:\", f1_score(Y_test, y_pred, average='micro'))\n",
        "print(\"F1 Macro:\", f1_score(Y_test, y_pred, average='macro'))\n",
        "print(\"ROC AUC (macro):\", roc_auc_score(Y_test, y_probs, average=\"macro\"))\n",
        "print(\"mAP:\", average_precision_score(Y_test, y_probs, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo8_5C6ykzr5",
        "outputId": "0ab1cbf6-9bb2-4067-c019-ed1f4f48e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     14149\n",
            "           1       0.00      0.00      0.00      5073\n",
            "           2       0.00      0.00      0.00      1887\n",
            "           3       0.00      0.00      0.00      1168\n",
            "           4       0.00      0.00      0.00       253\n",
            "           5       0.00      0.00      0.00      2457\n",
            "\n",
            "   micro avg       0.94      0.57      0.71     24987\n",
            "   macro avg       0.16      0.17      0.16     24987\n",
            "weighted avg       0.53      0.57      0.55     24987\n",
            " samples avg       0.94      0.65      0.75     24987\n",
            "\n",
            "F1 Micro: 0.7079809857393045\n",
            "F1 Macro: 0.16189528124856972\n",
            "ROC AUC (macro): 0.5\n",
            "mAP: 0.2779483414536475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_accuracy = np.all(Y_test == y_pred, axis=1).mean()\n",
        "print(\"Subset Accuracy (Exact Match):\", subset_accuracy)\n",
        "\n",
        "def multilabel_accuracy(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    union = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (intersection / (union + 1e-7)).mean()  # avoid division by zero\n",
        "\n",
        "sample_accuracy = multilabel_accuracy(Y_test, y_pred)\n",
        "print(\"Sample-wise Accuracy (Jaccard):\", sample_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOYY9ljEk2Lr",
        "outputId": "81bd886d-df86-4b2f-ab9d-2b1c165c19a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset Accuracy (Exact Match): 0.3863712207168124\n",
            "Sample-wise Accuracy (Jaccard): 0.6524949984308188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tune + Re-train"
      ],
      "metadata": {
        "id": "MJXPNIG2lnEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# build_model with an expanded search space\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Embedding(\n",
        "            input_dim=20000,\n",
        "            output_dim=hp.Int(\"embed_dim\", 64, 256, step=64),\n",
        "            input_length=100\n",
        "        ),\n",
        "        LSTM(\n",
        "            units=hp.Int(\"lstm_units\", 64, 256, step=64),\n",
        "            return_sequences=False\n",
        "        ),\n",
        "        Dropout(rate=hp.Float(\"dropout\", 0.2, 0.6, step=0.1)),\n",
        "        Dense(\n",
        "            units=hp.Int(\"dense_units\", 32, 128, step=32),\n",
        "            activation=hp.Choice(\"dense_activation\", [\"relu\", \"tanh\"])\n",
        "        ),\n",
        "        Dense(6, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    # optimizer choice + momentum\n",
        "    opt_name = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
        "    lr       = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
        "    if opt_name == \"adam\":\n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "    elif opt_name == \"rmsprop\":\n",
        "        optimizer = RMSprop(learning_rate=lr)\n",
        "    else:\n",
        "        optimizer = SGD(\n",
        "            learning_rate=lr,\n",
        "            momentum=hp.Float(\"momentum\", 0.0, 0.9, step=0.1)\n",
        "        )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# set up a RandomSearch over this bigger space\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=20,              # try more random configs\n",
        "    executions_per_trial=1,\n",
        "    directory=\"tuner_logs\",\n",
        "    project_name=\"multi_label_extended\"\n",
        ")\n",
        "\n",
        "# run the search for longer\n",
        "tuner.search(\n",
        "    X_train, Y_train,\n",
        "    epochs=15,                  # train each trial for 15 epochs\n",
        "    validation_data=(X_val, Y_val),\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# inspect & grab best\n",
        "tuner.results_summary()\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# further fine-tune the best model\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)\n",
        "\n",
        "best_model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr9baNP7KBTV",
        "outputId": "e12cd352-d709-4395-fc1a-0dfc1ed4f1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 03m 41s]\n",
            "val_loss: 0.3408079147338867\n",
            "\n",
            "Best val_loss So Far: 0.34071263670921326\n",
            "Total elapsed time: 01h 13m 12s\n",
            "Results summary\n",
            "Results in tuner_logs/multi_label_extended\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 15 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 256\n",
            "dropout: 0.2\n",
            "dense_units: 32\n",
            "dense_activation: tanh\n",
            "optimizer: sgd\n",
            "lr: 0.009279016033292642\n",
            "momentum: 0.1\n",
            "Score: 0.34071263670921326\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 192\n",
            "dropout: 0.4\n",
            "dense_units: 32\n",
            "dense_activation: tanh\n",
            "optimizer: rmsprop\n",
            "lr: 0.00011678341253394451\n",
            "momentum: 0.30000000000000004\n",
            "Score: 0.34072282910346985\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 192\n",
            "lstm_units: 256\n",
            "dropout: 0.2\n",
            "dense_units: 64\n",
            "dense_activation: tanh\n",
            "optimizer: adam\n",
            "lr: 0.00011079637617355325\n",
            "Score: 0.34072673320770264\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 64\n",
            "dropout: 0.30000000000000004\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: sgd\n",
            "lr: 0.0037577349709834304\n",
            "momentum: 0.0\n",
            "Score: 0.34072718024253845\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 64\n",
            "dropout: 0.2\n",
            "dense_units: 64\n",
            "dense_activation: tanh\n",
            "optimizer: rmsprop\n",
            "lr: 0.005085089360130894\n",
            "momentum: 0.6000000000000001\n",
            "Score: 0.34073108434677124\n",
            "\n",
            "Trial 18 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 128\n",
            "dropout: 0.30000000000000004\n",
            "dense_units: 32\n",
            "dense_activation: tanh\n",
            "optimizer: adam\n",
            "lr: 0.0002508748601218214\n",
            "momentum: 0.1\n",
            "Score: 0.34073522686958313\n",
            "\n",
            "Trial 13 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 256\n",
            "dropout: 0.4\n",
            "dense_units: 96\n",
            "dense_activation: tanh\n",
            "optimizer: sgd\n",
            "lr: 0.0007598433863293641\n",
            "momentum: 0.6000000000000001\n",
            "Score: 0.34073638916015625\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 256\n",
            "lstm_units: 192\n",
            "dropout: 0.4\n",
            "dense_units: 32\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.00017316634872800986\n",
            "momentum: 0.1\n",
            "Score: 0.3407454490661621\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 192\n",
            "lstm_units: 192\n",
            "dropout: 0.5\n",
            "dense_units: 32\n",
            "dense_activation: relu\n",
            "optimizer: adam\n",
            "lr: 0.0016069530933482345\n",
            "momentum: 0.7000000000000001\n",
            "Score: 0.3407537043094635\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 64\n",
            "dropout: 0.2\n",
            "dense_units: 32\n",
            "dense_activation: tanh\n",
            "optimizer: adam\n",
            "lr: 0.00016348395611442704\n",
            "Score: 0.34075456857681274\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1872/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9424 - loss: 0.3421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9424 - loss: 0.3421 - val_accuracy: 0.9427 - val_loss: 0.3407\n",
            "Epoch 2/20\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.3414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.3414 - val_accuracy: 0.9427 - val_loss: 0.3407\n",
            "Epoch 3/20\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.3414 - val_accuracy: 0.9427 - val_loss: 0.3407\n",
            "Epoch 4/20\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.3425 - val_accuracy: 0.9427 - val_loss: 0.3408\n",
            "Epoch 5/20\n",
            "\u001b[1m1873/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9438 - loss: 0.3403 - val_accuracy: 0.9427 - val_loss: 0.3407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a1c542ce5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted probabilities & binarize\n",
        "y_probs = best_model.predict(X_test)           # shape=(n_samples,6)\n",
        "y_pred  = (y_probs >= 0.5).astype(int)         # threshold at 0.5\n",
        "\n",
        "# Classification report & global scores\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "target_names = [str(i) for i in range(y_pred.shape[1])]\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(\n",
        "    Y_test, y_pred,\n",
        "    target_names=target_names,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "print(f\"F1 Micro  : {f1_score(Y_test, y_pred,    average='micro'):.4f}\")\n",
        "print(f\"F1 Macro  : {f1_score(Y_test, y_pred,    average='macro'):.4f}\")\n",
        "print(f\"ROC AUC   : {roc_auc_score(Y_test, y_probs, average='macro'):.4f}\")\n",
        "print(f\"mAP       : {average_precision_score(Y_test, y_probs, average='macro'):.4f}\")\n",
        "\n",
        "# Exact‐match (subset) accuracy\n",
        "subset_acc = np.all(Y_test == y_pred, axis=1).mean()\n",
        "print(f\"Subset Accuracy (Exact Match): {subset_acc:.4f}\")\n",
        "\n",
        "# Sample‐wise Jaccard (intersection/union) accuracy\n",
        "def jaccard_accuracy(y_true, y_pred):\n",
        "    inter = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    union = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (inter / (union + 1e-7)).mean()\n",
        "\n",
        "jaccard_acc = jaccard_accuracy(Y_test, y_pred)\n",
        "print(f\"Sample‐wise Jaccard Accuracy  : {jaccard_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6IrQJgVXS6E",
        "outputId": "100a526e-cc0b-454c-e89b-4bcfbe665e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     14149\n",
            "           1       0.00      0.00      0.00      5073\n",
            "           2       0.00      0.00      0.00      1887\n",
            "           3       0.00      0.00      0.00      1168\n",
            "           4       0.00      0.00      0.00       253\n",
            "           5       0.00      0.00      0.00      2457\n",
            "\n",
            "   micro avg       0.94      0.57      0.71     24987\n",
            "   macro avg       0.16      0.17      0.16     24987\n",
            "weighted avg       0.53      0.57      0.55     24987\n",
            " samples avg       0.94      0.65      0.75     24987\n",
            "\n",
            "F1 Micro  : 0.7080\n",
            "F1 Macro  : 0.1619\n",
            "ROC AUC   : 0.5007\n",
            "mAP       : 0.2778\n",
            "Subset Accuracy (Exact Match): 0.3864\n",
            "Sample‐wise Jaccard Accuracy  : 0.6525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pure Image model based on Resnet-18"
      ],
      "metadata": {
        "id": "SV0eopdtIkP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import libraries"
      ],
      "metadata": {
        "id": "O_U7Wu2eQ6cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "tmQgmXScO63N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load and Process Labels from JSON"
      ],
      "metadata": {
        "id": "J02q_P5VRDrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract image_id and label list\n",
        "records = []\n",
        "for image_id, content in data.items():\n",
        "    labels = content[\"labels\"]\n",
        "    records.append({\"image_id\": image_id, \"labels\": labels})  # label is a list\n",
        "\n",
        "img_df = pd.DataFrame(records)\n",
        "\n",
        "# Multi-label binarization\n",
        "mlb = MultiLabelBinarizer()\n",
        "multi_hot = mlb.fit_transform(img_df[\"labels\"])\n",
        "label_df = pd.DataFrame(multi_hot, columns=mlb.classes_)\n",
        "img_df = pd.concat([img_df[\"image_id\"], label_df], axis=1)"
      ],
      "metadata": {
        "id": "5iHDR9GpO8QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tNNT_IKkVtOJ",
        "outputId": "3449cfe9-9c03-4c3c-b542-878ec1e4f1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              image_id  0  1  2  3  4  5\n",
              "0  1114679353714016256  0  1  0  1  1  0\n",
              "1  1063020048816660480  0  0  0  0  0  1\n",
              "2  1108927368075374593  1  0  0  0  0  0\n",
              "3  1114558534635618305  1  1  0  0  0  0\n",
              "4  1035252480215592966  1  1  0  0  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e6b190f-e20a-4fac-8fb1-b4de3aba1753\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1114679353714016256</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1063020048816660480</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1108927368075374593</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1114558534635618305</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1035252480215592966</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e6b190f-e20a-4fac-8fb1-b4de3aba1753')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e6b190f-e20a-4fac-8fb1-b4de3aba1753 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e6b190f-e20a-4fac-8fb1-b4de3aba1753');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37b3175e-ff3b-4337-85d6-c369299bd4af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37b3175e-ff3b-4337-85d6-c369299bd4af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37b3175e-ff3b-4337-85d6-c369299bd4af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "img_df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train-Test Split"
      ],
      "metadata": {
        "id": "1GRMWQ3CRGXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    img_df,\n",
        "    test_size=0.2,\n",
        "    random_state=seed,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=seed,\n",
        ")"
      ],
      "metadata": {
        "id": "1gLqpJNpPDhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
        "print(\"Train label distribution:\\n\", train_df[mlb.classes_].sum())\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "KorwEgCgXESI",
        "outputId": "fe82f581-c7ca-4f36-9e24-0816f0a9c927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 119858, Val: 14982, Test: 14983\n",
            "Train label distribution:\n",
            " 0    112974\n",
            "1     39933\n",
            "2     15092\n",
            "3      9787\n",
            "4      1927\n",
            "5     19772\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   image_id  0  1  2  3  4  5\n",
              "54935   1115040489839796225  1  0  0  0  0  0\n",
              "30614   1113688240568057861  1  0  0  0  0  0\n",
              "49150   1062579213545492481  1  0  0  0  0  1\n",
              "92470   1062725606247264256  0  1  0  0  1  1\n",
              "129481  1113576678637408257  1  0  0  0  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d8bdefc-e5ab-43cd-81a7-fa15e5202f5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54935</th>\n",
              "      <td>1115040489839796225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30614</th>\n",
              "      <td>1113688240568057861</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49150</th>\n",
              "      <td>1062579213545492481</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92470</th>\n",
              "      <td>1062725606247264256</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129481</th>\n",
              "      <td>1113576678637408257</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8bdefc-e5ab-43cd-81a7-fa15e5202f5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d8bdefc-e5ab-43cd-81a7-fa15e5202f5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d8bdefc-e5ab-43cd-81a7-fa15e5202f5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23140368-8117-4a98-b268-69e034f8efd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23140368-8117-4a98-b268-69e034f8efd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23140368-8117-4a98-b268-69e034f8efd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define PyTorch Dataset Class"
      ],
      "metadata": {
        "id": "gtdM3qVLRKXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MMHSMultiLabelDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = df.columns[1:]  # exclude image_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row[\"image_id\"] + \".jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(row[self.label_cols].values.astype(\"float32\"), dtype=torch.float32)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "vu9JOFchPLHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set Up Transforms, DataLoader"
      ],
      "metadata": {
        "id": "zZgvmZALRNUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "image_dir = \"/content/MMHS150k/img_resized\"\n",
        "\n",
        "train_dataset = MMHSMultiLabelDataset(train_df, image_dir, transform)\n",
        "val_dataset   = MMHSMultiLabelDataset(val_df, image_dir, transform)\n",
        "test_dataset  = MMHSMultiLabelDataset(test_df, image_dir, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "HtzlVUiWPNri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define CNN Model and Training Loop"
      ],
      "metadata": {
        "id": "ITAqlazJRSwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ResNet18 and adapt last layer\n",
        "model_img = models.resnet18(pretrained=True)\n",
        "model_img.fc = nn.Linear(model_img.fc.in_features, len(train_df.columns) - 1)\n",
        "model_img = model_img.to(device)\n",
        "\n",
        "# Loss function for multi-label\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model_img.parameters(), lr=0.001)\n",
        "\n",
        "# Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training + validation loop\n",
        "for epoch in range(5):\n",
        "    model_img.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model_img(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model_img.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model_img(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmZJ7FMOPQ57",
        "outputId": "13016901-02d9-42ff-8262-a577999dc8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n",
            "<ipython-input-29-f881a5fd509a>:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-29-f881a5fd509a>:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-29-f881a5fd509a>:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.3437 | Val Loss: 0.3447\n",
            "Epoch 2 | Train Loss: 0.3415 | Val Loss: 0.3418\n",
            "Epoch 3 | Train Loss: 0.3402 | Val Loss: 0.3398\n",
            "Epoch 4 | Train Loss: 0.3392 | Val Loss: 0.3396\n",
            "Epoch 5 | Train Loss: 0.3379 | Val Loss: 0.3394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "uKywCnV-imwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score, average_precision_score\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "model_img.eval()\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_img(images)  # logits\n",
        "        probs = torch.sigmoid(outputs).cpu()  # convert to probabilities\n",
        "        all_probs.append(probs)\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all predictions and labels\n",
        "all_probs = torch.cat(all_probs).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# Binarize predictions at 0.5 threshold\n",
        "y_pred = (all_probs >= 0.5).astype(int)\n",
        "y_true = all_labels.astype(int)"
      ],
      "metadata": {
        "id": "1SvLiaqiYnIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "target_names = [str(c) for c in mlb.classes_]\n",
        "print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))\n",
        "print(\"F1 Micro:\", f1_score(y_true, y_pred, average='micro'))\n",
        "print(\"F1 Macro:\", f1_score(y_true, y_pred, average='macro'))\n",
        "print(\"ROC AUC (macro):\", roc_auc_score(y_true, all_probs, average=\"macro\"))\n",
        "print(\"mAP:\", average_precision_score(y_true, all_probs, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kjWXucjj554",
        "outputId": "6591866b-c146-40a3-c3aa-108643d7dd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     14123\n",
            "           1       0.00      0.00      0.00      4900\n",
            "           2       0.00      0.00      0.00      1924\n",
            "           3       0.00      0.00      0.00      1219\n",
            "           4       0.00      0.00      0.00       241\n",
            "           5       0.00      0.00      0.00      2443\n",
            "\n",
            "   micro avg       0.94      0.57      0.71     24850\n",
            "   macro avg       0.16      0.17      0.16     24850\n",
            "weighted avg       0.54      0.57      0.55     24850\n",
            " samples avg       0.94      0.66      0.75     24850\n",
            "\n",
            "F1 Micro: 0.7091283390239004\n",
            "F1 Macro: 0.1617476951268396\n",
            "ROC AUC (macro): 0.557358759343425\n",
            "mAP: 0.3042656524753261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy metrics\n",
        "subset_accuracy = np.all(y_pred == y_true, axis=1).mean()\n",
        "print(\"Subset Accuracy (Exact Match):\", subset_accuracy)\n",
        "\n",
        "def multilabel_accuracy(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    union = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (intersection / (union + 1e-7)).mean()\n",
        "\n",
        "sample_accuracy = multilabel_accuracy(y_true, y_pred)\n",
        "print(\"Sample-wise Accuracy (Jaccard):\", sample_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSPRN4t1by46",
        "outputId": "8ab9a824-feed-4294-920f-83f78c1fedb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset Accuracy (Exact Match): 0.3933386730743559\n",
            "Sample-wise Accuracy (Jaccard): 0.6555755275528827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tune"
      ],
      "metadata": {
        "id": "sRJUd9_uSPLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from itertools import product\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the search space\n",
        "search_space = {\n",
        "    \"learning_rate\": [1e-4, 1e-3, 1e-2],\n",
        "    \"batch_size\": [32, 64],\n",
        "    \"weight_decay\": [0, 1e-4, 1e-5],\n",
        "    \"optimizer\": [\"adam\", \"sgd\"],\n",
        "    \"epochs\": [5],\n",
        "}\n",
        "\n",
        "# Randomly sample N combinations\n",
        "num_trials = 5\n",
        "random.seed(2025)\n",
        "param_combinations = random.sample(list(product(*search_space.values())), num_trials)\n",
        "\n",
        "# Mapping for search_space keys\n",
        "keys = list(search_space.keys())\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_params = None\n",
        "\n",
        "for trial_idx, combo in enumerate(param_combinations):\n",
        "    # Unpack parameters\n",
        "    params = dict(zip(keys, combo))\n",
        "    lr = params[\"learning_rate\"]\n",
        "    batch_size = params[\"batch_size\"]\n",
        "    weight_decay = params[\"weight_decay\"]\n",
        "    optimizer_type = params[\"optimizer\"]\n",
        "    epochs = params[\"epochs\"]\n",
        "\n",
        "    print(f\"\\n=== Trial {trial_idx + 1} / {num_trials} ===\")\n",
        "    print(params)\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Model\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(train_df.columns) - 1)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    if optimizer_type == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
        "\n",
        "    # Loss + Scaler\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Track best config\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_params = params\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(\"\\n=== Best Hyperparameters ===\")\n",
        "print(best_params)\n",
        "print(\"Best Validation Loss:\", best_val_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7syf8HrUSOuq",
        "outputId": "30e2225f-e36e-4c09-ee23-b6dbcb3d6fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Trial 1 / 5 ===\n",
            "{'learning_rate': 0.01, 'batch_size': 64, 'weight_decay': 1e-05, 'optimizer': 'sgd', 'epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-681e00a09b47>:60: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-17-681e00a09b47>:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-17-681e00a09b47>:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.3352 | Val Loss: 0.3315\n",
            "Epoch 2 | Train Loss: 0.3239 | Val Loss: 0.3286\n",
            "Epoch 3 | Train Loss: 0.3136 | Val Loss: 0.3350\n",
            "Epoch 4 | Train Loss: 0.2986 | Val Loss: 0.3403\n",
            "Epoch 5 | Train Loss: 0.2776 | Val Loss: 0.3610\n",
            "\n",
            "=== Trial 2 / 5 ===\n",
            "{'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05, 'optimizer': 'sgd', 'epochs': 5}\n",
            "Epoch 1 | Train Loss: 0.3512 | Val Loss: 0.3416\n",
            "Epoch 2 | Train Loss: 0.3390 | Val Loss: 0.3375\n",
            "Epoch 3 | Train Loss: 0.3358 | Val Loss: 0.3357\n",
            "Epoch 4 | Train Loss: 0.3342 | Val Loss: 0.3342\n",
            "Epoch 5 | Train Loss: 0.3328 | Val Loss: 0.3333\n",
            "\n",
            "=== Trial 3 / 5 ===\n",
            "{'learning_rate': 0.01, 'batch_size': 64, 'weight_decay': 0, 'optimizer': 'adam', 'epochs': 5}\n",
            "Epoch 1 | Train Loss: 0.3460 | Val Loss: 0.3424\n",
            "Epoch 2 | Train Loss: 0.3416 | Val Loss: 0.3412\n",
            "Epoch 3 | Train Loss: 0.3411 | Val Loss: 0.3401\n",
            "Epoch 4 | Train Loss: 0.3403 | Val Loss: 0.3406\n",
            "Epoch 5 | Train Loss: 0.3393 | Val Loss: 0.3390\n",
            "\n",
            "=== Trial 4 / 5 ===\n",
            "{'learning_rate': 0.0001, 'batch_size': 64, 'weight_decay': 1e-05, 'optimizer': 'sgd', 'epochs': 5}\n",
            "Epoch 1 | Train Loss: 0.3599 | Val Loss: 0.3449\n",
            "Epoch 2 | Train Loss: 0.3425 | Val Loss: 0.3409\n",
            "Epoch 3 | Train Loss: 0.3392 | Val Loss: 0.3385\n",
            "Epoch 4 | Train Loss: 0.3371 | Val Loss: 0.3369\n",
            "Epoch 5 | Train Loss: 0.3357 | Val Loss: 0.3359\n",
            "\n",
            "=== Trial 5 / 5 ===\n",
            "{'learning_rate': 0.01, 'batch_size': 64, 'weight_decay': 0.0001, 'optimizer': 'sgd', 'epochs': 5}\n",
            "Epoch 1 | Train Loss: 0.3358 | Val Loss: 0.3280\n",
            "Epoch 2 | Train Loss: 0.3238 | Val Loss: 0.3298\n",
            "Epoch 3 | Train Loss: 0.3136 | Val Loss: 0.3328\n",
            "Epoch 4 | Train Loss: 0.2993 | Val Loss: 0.3422\n",
            "Epoch 5 | Train Loss: 0.2796 | Val Loss: 0.3589\n",
            "\n",
            "=== Best Hyperparameters ===\n",
            "{'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 1e-05, 'optimizer': 'sgd', 'epochs': 5}\n",
            "Best Validation Loss: 0.3333118503599533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Again With the Optimal Hyperparameters"
      ],
      "metadata": {
        "id": "uKwccPm2rK-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ResNet18 and adapt last layer\n",
        "model_img = models.resnet18(pretrained=True)\n",
        "model_img.fc = nn.Linear(model_img.fc.in_features, len(train_df.columns) - 1)\n",
        "model_img = model_img.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer with best hyperparameters\n",
        "optimizer = optim.SGD(model_img.parameters(), lr=0.0001, weight_decay=1e-5, momentum=0.9)\n",
        "\n",
        "# Mixed precision scaler\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training + validation loop\n",
        "for epoch in range(10):  # epochs = 10\n",
        "    model_img.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model_img(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model_img.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model_img(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O6qiglDsOnk",
        "outputId": "26bb9160-888d-4668-9a95-e3055ba7a5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-30373b8cad5c>:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-18-30373b8cad5c>:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-18-30373b8cad5c>:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.3644 | Val Loss: 0.3466\n",
            "Epoch 2 | Train Loss: 0.3437 | Val Loss: 0.3422\n",
            "Epoch 3 | Train Loss: 0.3402 | Val Loss: 0.3397\n",
            "Epoch 4 | Train Loss: 0.3379 | Val Loss: 0.3381\n",
            "Epoch 5 | Train Loss: 0.3364 | Val Loss: 0.3369\n",
            "Epoch 6 | Train Loss: 0.3353 | Val Loss: 0.3359\n",
            "Epoch 7 | Train Loss: 0.3343 | Val Loss: 0.3353\n",
            "Epoch 8 | Train Loss: 0.3336 | Val Loss: 0.3346\n",
            "Epoch 9 | Train Loss: 0.3328 | Val Loss: 0.3341\n",
            "Epoch 10 | Train Loss: 0.3322 | Val Loss: 0.3337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score, average_precision_score\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "model_img.eval()\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_img(images)  # logits\n",
        "        probs = torch.sigmoid(outputs).cpu()  # convert to probabilities\n",
        "        all_probs.append(probs)\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all predictions and labels\n",
        "all_probs = torch.cat(all_probs).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# Binarize predictions at 0.5 threshold\n",
        "y_pred = (all_probs >= 0.5).astype(int)\n",
        "y_true = all_labels.astype(int)"
      ],
      "metadata": {
        "id": "MOPTbiKF2uzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy metrics\n",
        "subset_accuracy = np.all(y_pred == y_true, axis=1).mean()\n",
        "print(\"Subset Accuracy (Exact Match):\", subset_accuracy)\n",
        "\n",
        "def multilabel_accuracy(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    union = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (intersection / (union + 1e-7)).mean()\n",
        "\n",
        "sample_accuracy = multilabel_accuracy(y_true, y_pred)\n",
        "print(\"Sample-wise Accuracy (Jaccard):\", sample_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOZ_0Gic22dX",
        "outputId": "d3b58385-0daa-4b25-a226-f6c864f91d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset Accuracy (Exact Match): 0.3957415565345081\n",
            "Sample-wise Accuracy (Jaccard): 0.6577058620840888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Captioning+Text Extract Model+LSTM"
      ],
      "metadata": {
        "id": "fs616-HGgdcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Divide images into two groups(in-image text/no in-image text)"
      ],
      "metadata": {
        "id": "Jo622sRg8-Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "roUkeypOmTRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "_vEv1UUhyJrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/MMHS150k/img_resized\""
      ],
      "metadata": {
        "id": "6_QQQo3T83lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_text_pairs = []\n",
        "\n",
        "for image_id, content in data.items():\n",
        "    image_file = image_id + \".jpg\"  # Add extension\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "\n",
        "    tweet_text = content.get(\"tweet_text\", \"\")\n",
        "    if os.path.exists(image_path):\n",
        "        image_text_pairs.append((image_path, tweet_text))\n",
        "\n",
        "print(f\"Total matched image-text pairs: {len(image_text_pairs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMYukCmmrHAH",
        "outputId": "29cc88ce-0037-4b39-d4fd-8f770233a7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matched image-text pairs: 149823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EasyOCR\n",
        "import easyocr\n",
        "from tqdm import tqdm\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Two groups\n",
        "text_images = []\n",
        "non_text_images = []\n",
        "\n",
        "# Use EasyOCR to detect the existence of in-image text in each image and group images\n",
        "for path, tweet in tqdm(image_text_pairs):\n",
        "    try:\n",
        "        result = reader.readtext(path, detail=0)\n",
        "        result_text = ' '.join(result).strip().lower()\n",
        "\n",
        "        if not result or result_text in [\"\", \"na\", \"n/a\"]:\n",
        "            non_text_images.append((path, tweet))\n",
        "        else:\n",
        "            text_images.append((path, tweet))\n",
        "    except Exception as e:\n",
        "        print(f\"Failed OCR on {path}: {e}\")\n",
        "        non_text_images.append((path, tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtioE1RP22Tk",
        "outputId": "d886d421-77e1-42c5-a394-940e95ba0d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149823/149823 [2:31:42<00:00, 16.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(text_images, columns=[\"image_path\", \"tweet_text\"]).to_csv(\"text_images.csv\", index=False)\n",
        "pd.DataFrame(non_text_images, columns=[\"image_path\", \"tweet_text\"]).to_csv(\"non_text_images.csv\", index=False)"
      ],
      "metadata": {
        "id": "lVUVN6G33kto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text Extraction(for in-image text group)"
      ],
      "metadata": {
        "id": "di_9hEpz9XFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Perform text extraction"
      ],
      "metadata": {
        "id": "QQm50hxcDBtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text_image csv we have obtained above\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"text_images.csv\")"
      ],
      "metadata": {
        "id": "ACE4uvj-9i6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Similar implementation as before\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "ocr_results = []\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    path = row[\"image_path\"]\n",
        "    tweet = row[\"tweet_text\"]\n",
        "    try:\n",
        "        result = reader.readtext(path, detail=0)\n",
        "        ocr_text = ' '.join(result).strip()\n",
        "    except Exception as e:\n",
        "        ocr_text = f\"[OCR_ERROR]: {e}\"\n",
        "    combined = tweet.strip() + \" \" + ocr_text\n",
        "    ocr_results.append({\n",
        "        \"image_path\": path,\n",
        "        \"tweet_text\": tweet,\n",
        "        \"ocr_text\": ocr_text,\n",
        "        \"combined_text\": combined\n",
        "    })\n",
        "\n",
        "# Save to CSV in one go\n",
        "df_out = pd.DataFrame(ocr_results)\n",
        "df_out.to_csv(\"text_images_with_ocr_combined.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALXxeZzwAh1q",
        "outputId": "0d432098-60e1-4f76-d16a-0673309e08e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74955/74955 [1:58:46<00:00, 10.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data cleaning for combined text"
      ],
      "metadata": {
        "id": "4JtzsIx0DWR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Clean tweet_text: same as the one in baseline model\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", '', text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", '', text)            # Remove mentions\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", '', text)     # Remove special characters\n",
        "    return text.lower().strip()"
      ],
      "metadata": {
        "id": "MWgdzE0aDT0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the generated csv\n",
        "df_ext = pd.read_csv('/content/text_images_with_ocr_combined.csv')\n",
        "df_ext.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O0-rT7ZfDj5d",
        "outputId": "c3e65ae0-be03-4a65-c91a-c4135f517ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path  \\\n",
              "0  /content/MMHS150k/img_resized/1114679353714016...   \n",
              "1  /content/MMHS150k/img_resized/1063020048816660...   \n",
              "2  /content/MMHS150k/img_resized/1113920043568463...   \n",
              "3  /content/MMHS150k/img_resized/1114588617693966...   \n",
              "4  /content/MMHS150k/img_resized/1045809514740666...   \n",
              "\n",
              "                                          tweet_text  \\\n",
              "0       @FriskDontMiss Nigga https://t.co/cAsaLWEpue   \n",
              "1     My horses are retarded https://t.co/HYhqc6d5WN   \n",
              "2  @WhiteHouse @realDonaldTrump Fuck ice. White s...   \n",
              "3               Day’s a cunt https://t.co/Ie6QZReHsw   \n",
              "4              #sissy faggot https://t.co/bm1nk8HcYO   \n",
              "\n",
              "                                            ocr_text  \\\n",
              "0                                  #YOUNGERT SAVE IT   \n",
              "1      Shuw Lifv @U Wilui Fzz Fulwy 4 Sm 0 Fz 0 Juxt   \n",
              "2  Hello, White Nationalist: Good-bye Others will...   \n",
              "3  Dad's a @CQunt COUNcL ESIAWw Mum's a @Qunt @ N...   \n",
              "4  EVERY SissyagirL SHOULd KvOw hal MEv (Re NZARD...   \n",
              "\n",
              "                                       combined_text  \n",
              "0  @FriskDontMiss Nigga https://t.co/cAsaLWEpue #...  \n",
              "1  My horses are retarded https://t.co/HYhqc6d5WN...  \n",
              "2  @WhiteHouse @realDonaldTrump Fuck ice. White s...  \n",
              "3  Day’s a cunt https://t.co/Ie6QZReHsw Dad's a @...  \n",
              "4  #sissy faggot https://t.co/bm1nk8HcYO EVERY Si...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de2cbd68-c8ef-4dbc-b873-081f73703f44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>ocr_text</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/MMHS150k/img_resized/1114679353714016...</td>\n",
              "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue</td>\n",
              "      <td>#YOUNGERT SAVE IT</td>\n",
              "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/MMHS150k/img_resized/1063020048816660...</td>\n",
              "      <td>My horses are retarded https://t.co/HYhqc6d5WN</td>\n",
              "      <td>Shuw Lifv @U Wilui Fzz Fulwy 4 Sm 0 Fz 0 Juxt</td>\n",
              "      <td>My horses are retarded https://t.co/HYhqc6d5WN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/MMHS150k/img_resized/1113920043568463...</td>\n",
              "      <td>@WhiteHouse @realDonaldTrump Fuck ice. White s...</td>\n",
              "      <td>Hello, White Nationalist: Good-bye Others will...</td>\n",
              "      <td>@WhiteHouse @realDonaldTrump Fuck ice. White s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/MMHS150k/img_resized/1114588617693966...</td>\n",
              "      <td>Day’s a cunt https://t.co/Ie6QZReHsw</td>\n",
              "      <td>Dad's a @CQunt COUNcL ESIAWw Mum's a @Qunt @ N...</td>\n",
              "      <td>Day’s a cunt https://t.co/Ie6QZReHsw Dad's a @...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/MMHS150k/img_resized/1045809514740666...</td>\n",
              "      <td>#sissy faggot https://t.co/bm1nk8HcYO</td>\n",
              "      <td>EVERY SissyagirL SHOULd KvOw hal MEv (Re NZARD...</td>\n",
              "      <td>#sissy faggot https://t.co/bm1nk8HcYO EVERY Si...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de2cbd68-c8ef-4dbc-b873-081f73703f44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de2cbd68-c8ef-4dbc-b873-081f73703f44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de2cbd68-c8ef-4dbc-b873-081f73703f44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09a92fd9-af68-46e2-ba02-ebaacce90437\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09a92fd9-af68-46e2-ba02-ebaacce90437')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09a92fd9-af68-46e2-ba02-ebaacce90437 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ext",
              "summary": "{\n  \"name\": \"df_ext\",\n  \"rows\": 74955,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74955,\n        \"samples\": [\n          \"/content/MMHS150k/img_resized/1107999781190799361.jpg\",\n          \"/content/MMHS150k/img_resized/1108164934851022849.jpg\",\n          \"/content/MMHS150k/img_resized/1062557909274349568.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74881,\n        \"samples\": [\n          \"Anyone want to take one for the team #sjw https://t.co/zRL9kfd6jw\",\n          \"Let a nigga know if its smoke  #PS4share https://t.co/JrxWbmYJZr\",\n          \"@LeadingNFL This man is retarded \\ud83e\\udd26\\u200d\\u2642\\ufe0f https://t.co/yrW38pWc22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocr_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59010,\n        \"samples\": [\n          \"Vmas\",\n          \"Kyrie Fan Jags ( 3-3) Celtics ( 1-1) @PrimeFourn__. Zm A Lol. twitter com/Soslamy23/stat This Tweet is unavailable 0 2\",\n          \"Let's just eat for now:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74884,\n        \"samples\": [\n          \"Looks who\\u2019s a faggot https://t.co/LcvGCWIXf0 SHAN ,\",\n          \"@BJLAFLARE7 Nigga said https://t.co/oiclwf5raV cafeeUNfMMEAFMR | Tuiofie\",\n          \"This much trash in a very small area DONT BE A CUNT AND LITTER https://t.co/lWV0kdkJLe ) ObSTacle IoverheadC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean\n",
        "df_ext[\"combined_text\"] = df_ext[\"combined_text\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "QtE4awrCEEPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect\n",
        "df_ext['combined_text'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SoiZBTeVEZC3",
        "outputId": "e472c308-12f5-4cf2-abce-2310a4c88a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                              nigga  youngert save it\n",
              "1    my horses are retarded  shuw lifv  wilui fzz f...\n",
              "2    fuck ice white supremacist trash all of you ar...\n",
              "3    days a cunt  dads a  councl esiaww mums a   na...\n",
              "4    sissy faggot  every sissyagirl should kvow hal...\n",
              "Name: combined_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nigga  youngert save it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my horses are retarded  shuw lifv  wilui fzz f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fuck ice white supremacist trash all of you ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>days a cunt  dads a  councl esiaww mums a   na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sissy faggot  every sissyagirl should kvow hal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Captioning(for non in-image text group)"
      ],
      "metadata": {
        "id": "Ft7GCj3HJb2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Data and Cleaning"
      ],
      "metadata": {
        "id": "WkgLu_a4NeBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_cap = pd.read_csv('non_text_images.csv')\n",
        "df_cap.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QQH0O8iEJYFP",
        "outputId": "0c578b0f-38ad-4a36-955b-57192f6582f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path  \\\n",
              "0  /content/MMHS150k/img_resized/1108927368075374...   \n",
              "1  /content/MMHS150k/img_resized/1114558534635618...   \n",
              "2  /content/MMHS150k/img_resized/1035252480215592...   \n",
              "3  /content/MMHS150k/img_resized/1106978219654303...   \n",
              "4  /content/MMHS150k/img_resized/1108178453910695...   \n",
              "\n",
              "                                          tweet_text  \n",
              "0  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...  \n",
              "1  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...  \n",
              "2  “EVERYbody calling you Nigger now!” https://t....  \n",
              "3  “ real ass bitch give a fuck boutta nigga” htt...  \n",
              "4      @Gloriko_ Nigga what? https://t.co/nOwIJtgtU1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-237b9588-a69a-4e83-a12c-5b51d5335ebc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108927368075374...</td>\n",
              "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/MMHS150k/img_resized/1114558534635618...</td>\n",
              "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/MMHS150k/img_resized/1035252480215592...</td>\n",
              "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/MMHS150k/img_resized/1106978219654303...</td>\n",
              "      <td>“ real ass bitch give a fuck boutta nigga” htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108178453910695...</td>\n",
              "      <td>@Gloriko_ Nigga what? https://t.co/nOwIJtgtU1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-237b9588-a69a-4e83-a12c-5b51d5335ebc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-237b9588-a69a-4e83-a12c-5b51d5335ebc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-237b9588-a69a-4e83-a12c-5b51d5335ebc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-598a2df7-bff3-4f66-897b-758b771a93cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-598a2df7-bff3-4f66-897b-758b771a93cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-598a2df7-bff3-4f66-897b-758b771a93cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cap",
              "summary": "{\n  \"name\": \"df_cap\",\n  \"rows\": 74868,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74868,\n        \"samples\": [\n          \"/content/MMHS150k/img_resized/1110384608976216064.jpg\",\n          \"/content/MMHS150k/img_resized/1108130695010897921.jpg\",\n          \"/content/MMHS150k/img_resized/1110405598976360448.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74823,\n        \"samples\": [\n          \"Real Nigga Selfies https://t.co/6OPEMgNJuz\",\n          \"Van Dyke Trial Resumes\\u00a0Monday https://t.co/Ht7bya6V3N https://t.co/VfYkG0vNI2\",\n          \"@SeoYeongChae_ not to start smoke but we reallly been letting cardi b say nigga for awhile now too https://t.co/YR4ZM9YKbY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "from PIL import Image\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Clean tweet_text: same as the one in baseline model\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", '', text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", '', text)            # Remove mentions\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", '', text)     # Remove special characters\n",
        "    return text.lower().strip()\n",
        "\n",
        "df_cap[\"tweet_text\"] = df_cap[\"tweet_text\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "5iX1LXckJ6im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cap.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mLUDrtYINFMZ",
        "outputId": "73766358-6ecd-4c4c-88de-0702db78b971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path  \\\n",
              "0  /content/MMHS150k/img_resized/1108927368075374...   \n",
              "1  /content/MMHS150k/img_resized/1114558534635618...   \n",
              "2  /content/MMHS150k/img_resized/1035252480215592...   \n",
              "3  /content/MMHS150k/img_resized/1106978219654303...   \n",
              "4  /content/MMHS150k/img_resized/1108178453910695...   \n",
              "\n",
              "                                          tweet_text  \n",
              "0  nigga on ma momma youngboy be spitting real sh...  \n",
              "1     rt xxsugvngxx i ran into this holy nigga today  \n",
              "2                   everybody calling you nigger now  \n",
              "3            real ass bitch give a fuck boutta nigga  \n",
              "4                                         nigga what  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cec500b4-ed5b-49fd-a11a-8dd2aaf2aa2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108927368075374...</td>\n",
              "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/MMHS150k/img_resized/1114558534635618...</td>\n",
              "      <td>rt xxsugvngxx i ran into this holy nigga today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/MMHS150k/img_resized/1035252480215592...</td>\n",
              "      <td>everybody calling you nigger now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/MMHS150k/img_resized/1106978219654303...</td>\n",
              "      <td>real ass bitch give a fuck boutta nigga</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108178453910695...</td>\n",
              "      <td>nigga what</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cec500b4-ed5b-49fd-a11a-8dd2aaf2aa2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cec500b4-ed5b-49fd-a11a-8dd2aaf2aa2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cec500b4-ed5b-49fd-a11a-8dd2aaf2aa2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02e569e1-248f-4f56-957e-2f3d068822f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02e569e1-248f-4f56-957e-2f3d068822f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02e569e1-248f-4f56-957e-2f3d068822f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cap",
              "summary": "{\n  \"name\": \"df_cap\",\n  \"rows\": 74868,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74868,\n        \"samples\": [\n          \"/content/MMHS150k/img_resized/1110384608976216064.jpg\",\n          \"/content/MMHS150k/img_resized/1108130695010897921.jpg\",\n          \"/content/MMHS150k/img_resized/1110405598976360448.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66891,\n        \"samples\": [\n          \"the dyke jumped out\",\n          \"was that your best comeback you twat\",\n          \"i love letting this nigga fuck me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Captioning Model using VisionEncoderDecoderModel"
      ],
      "metadata": {
        "id": "RuSb_vcUNitz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VisionEncoderDecoderModel\n",
        "model_name = \"nlpconnect/vit-gpt2-image-captioning\"\n",
        "model_cap = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_cap.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "55c2f1fed2124a4facbde1a59df741a3",
            "fd3ca65007664bdb98513526e3bf2a65",
            "afaeb1ead02c4b729a0b3b3b3582b58a",
            "2f8457a5e5cf4c118ea4e82a342fe0e7",
            "27c21ffdc6e34eb5a63ac7113bf9b3d4",
            "a406ba8c108a4ffab5044d14dea2a398",
            "3ddfa58d0c014717b3791eb2e10771c1",
            "c35584509ebf43c79ba24ed00308d448",
            "a9d918ae34974c94b030a1f56d62c0f0",
            "f0ba02521a75469e8d4a02bb66f5033e",
            "f68197be7eb6419192a1667c3339dfaf",
            "c2d96c9b8f3c4afd992e8245b07f9c16",
            "079aa32ae0614da0b1f33418c0ea528c",
            "7593600bddfd461fa859085ffea7ce6c",
            "287c570488684bb59e8542aad212c3dc",
            "7ca18974015e4e70b6b4746dc5f775a1",
            "875da9a8e998447ea92697b4ca1518f3",
            "e747bc6806a44999a3397833d353a460",
            "d1cf267972c141b49cf5605dd2de3292",
            "893bd033ed014d5e8b19d437bca94fb1",
            "f1f2cd8907e948e7b9ad6b226d51431b",
            "fc1840881d6c4ecb812636868f632aa6",
            "be8a3545c3744353ac969b51a3504f54",
            "5b04be7f85f943a1a0da6312640518d9",
            "b95371d1d9e04de3b2a4c31d5128ac55",
            "ac3af0bb0b364bc0946ca38385081da4",
            "947f5ec4423247cf8a0b17c50f721098",
            "0f37d533d55d44199e08500b7f833c72",
            "e2fb12330ea2435c8fad4499b4fc23fd",
            "da80a34f4f2447c19fdfd039b5ad486e",
            "1cccd535679e4834ac400297212d38c2",
            "90b66aaf7bb94beb889abda7aae2f1ee",
            "e76441224f2c42f1bacfec9de8257120",
            "70a69551cd9745c3b87d5f7bf715d4da",
            "9d0a0ed404dc45bc955662d4bc443979",
            "7a2966d5fd1645ed970c6cec203c823f",
            "a7fd465e445e4befb3d4c7d4a4d20d8e",
            "8be1978ebcd24556a2baf56a37239b67",
            "d114ed0fce9a4f27b499507b01cf5439",
            "95e7b990d22e4651bcb64055671360c9",
            "ffb60e0e0b9a46b8bf6673ca18a38e95",
            "b077fb1bcf1b433c9652d6d6331cf929",
            "fd738c049c0941299647cab6ea6e6e14",
            "539d6f01228d4706aedea6cd180e4cca",
            "1d2efad6cd6f46c38ce1aceadac3e53a",
            "a6e845e2bea54551a910cd4e5a06f701",
            "d01222ac378343949ccc0aa65b86de5a",
            "65ad590278064667bafafeb630d8921d",
            "8cbdef3dc57f408da136b9733185aaeb",
            "53fa41b813e74d1aa95852e15007369b",
            "d6f0dc56bbb746a38a7821dd416a1984",
            "3512b4e656d54ad38e15774e84bd5f08",
            "4830a192601b4880a7bf4674f7aad09b",
            "de3921e1f05b4e95b06f8dc4c2adf31f",
            "dfb490fe385746ccac826ebbce9849ab",
            "97083cd54c7b4472b14e97266eef0ea8",
            "c2516987e5e74a878d3fa69575d7657d",
            "a8c9f6913dde46be8485094d2ee87a79",
            "88633b60ce864e8c835b7ce4e744f26c",
            "d3051e75c1b64fe0b5106f64b1527716",
            "a49a13925c9d41db8f302927c667af6b",
            "a90703072e164e3b99e6ad809eba7a73",
            "6bea5a252a634ae992220ec552d2272c",
            "7749a1e730614c4d83f7b9c18126c445",
            "3435031170eb4587986735b4e10018de",
            "e3668fef56df47f7b9a4c336456a1fd6",
            "61c25e71ba5446a988eefa60defd48a8",
            "67ac114de1ab496fa4b0fcc916179e32",
            "5abd3115ec0f4aeba03165898ac7ad4c",
            "8da618213a454aef98c2395f765b0114",
            "e61d00e8a94b4f28988e2625ad1f509f",
            "7312c335f6a447cd926303737a6f7832",
            "b14ac52a314f480eaa6697edfb8237c0",
            "762bc7d51fdf40f38be4d7b74346682e",
            "2a6c2a0aac2d488bbc1c04bb399a30e8",
            "c2f19d410eb7423091636e001e46475e",
            "ac265b73d4954cb499d3fb74f4b920f3",
            "c90c57ea973b4c6bb0e9858df1f2cdb1",
            "d9eddb64aaad48d19986fd66549568e5",
            "409385b82bc64276bedfd417bf7c34c7",
            "595e0c46e04942319d2ec3a320c0afa3",
            "ff84b089149f4921be0594d9b5d0283a",
            "119818a0cb764258bd546f3bd128d08c",
            "f51bbdb34e5b4c6cbe8d2365360b21e0",
            "5077617dbc5646958e791ff5d6044060",
            "fc22f0f510ff4149be32f2972e590f4c",
            "7668c608764e4c00948963969e4c73c6",
            "cfb45fe03b574c439a0df76aa896df52",
            "175514884db944fd971d0af95c1fec10",
            "b1d6a199557e49e3aad315031c43e7c9",
            "05afbc06dc6941d287ae081c23bc0d59",
            "9e253a3b41ca461eae15372da4a1f802",
            "2c97e26b06b5446e9f90cf98fffc87a6",
            "80cf00d54b8546e3952ddd1bbd3eae81",
            "0337ae0bd709436cbecfae1195e122a0",
            "6881319162ff4315b7ef447665a76042",
            "63b549907bae47178078beeed389bac5",
            "b302c9ff41ee466ca4e7d4c035c52b50",
            "a775a81ab6624c3e90485710894da7ff"
          ]
        },
        "id": "VNosqCuFMc5l",
        "outputId": "0f411f37-5910-42d6-ca31-9b14ce8ce19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c2f1fed2124a4facbde1a59df741a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2d96c9b8f3c4afd992e8245b07f9c16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/982M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be8a3545c3744353ac969b51a3504f54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"pooler_act\": \"tanh\",\n",
            "  \"pooler_output_size\": 768,\n",
            "  \"qkv_bias\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70a69551cd9745c3b87d5f7bf715d4da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/241 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d2efad6cd6f46c38ce1aceadac3e53a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97083cd54c7b4472b14e97266eef0ea8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c25e71ba5446a988eefa60defd48a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c90c57ea973b4c6bb0e9858df1f2cdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "175514884db944fd971d0af95c1fec10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (pooler): ViTPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): GPT2LMHeadModel(\n",
              "    (transformer): GPT2Model(\n",
              "      (wte): Embedding(50257, 768)\n",
              "      (wpe): Embedding(1024, 768)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0-11): 12 x GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D(nf=2304, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=768)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (crossattention): GPT2Attention(\n",
              "            (c_attn): Conv1D(nf=1536, nx=768)\n",
              "            (q_attn): Conv1D(nf=768, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=768)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D(nf=3072, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=3072)\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Caption the images"
      ],
      "metadata": {
        "id": "8epqT_qYNppP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image_path):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "        pixel_values = pixel_values.to(device)\n",
        "        output_ids = model_cap.generate(pixel_values, max_length=16, num_beams=4)\n",
        "        caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    except Exception as e:\n",
        "        return \"\"\n",
        "\n",
        "# Generate combined text\n",
        "results = []\n",
        "\n",
        "for idx, row in tqdm(df_cap.iterrows(), total=len(df_cap)):\n",
        "    path = row[\"image_path\"]\n",
        "    tweet = row[\"tweet_text\"]\n",
        "    caption = generate_caption(path)\n",
        "    combined = tweet + \" \" + caption\n",
        "    results.append({\n",
        "        \"image_path\": path,\n",
        "        \"tweet_text\": tweet,\n",
        "        \"caption_text\": caption,\n",
        "        \"combined_text\": combined\n",
        "    })\n",
        "\n",
        "# Store in new dataframe\n",
        "result_df_cap = pd.DataFrame(results)\n",
        "result_df_cap.to_csv(\"img2text_captions.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii3W6fZbMnro",
        "outputId": "cf81bf3c-6782-4851-b809-550fac4f30df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74868/74868 [5:02:29<00:00,  4.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing if generate_caption is working\n",
        "test_path = \"/content/MMHS150k/img_resized/1108927368075374593.jpg\"\n",
        "print(generate_caption(test_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94302785-0582-402a-d69b-5f5bf133d994",
        "id": "ntahYnXwTH5l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a man is using a comb to cut his hair \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_cap.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ysKuD7VMNuK1",
        "outputId": "aacd601e-b19f-4d05-9c19-cf1d0d2bbe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path  \\\n",
              "0  /content/MMHS150k/img_resized/1108927368075374...   \n",
              "1  /content/MMHS150k/img_resized/1114558534635618...   \n",
              "2  /content/MMHS150k/img_resized/1035252480215592...   \n",
              "3  /content/MMHS150k/img_resized/1106978219654303...   \n",
              "4  /content/MMHS150k/img_resized/1108178453910695...   \n",
              "\n",
              "                                          tweet_text  \\\n",
              "0  nigga on ma momma youngboy be spitting real sh...   \n",
              "1     rt xxsugvngxx i ran into this holy nigga today   \n",
              "2                   everybody calling you nigger now   \n",
              "3            real ass bitch give a fuck boutta nigga   \n",
              "4                                         nigga what   \n",
              "\n",
              "                                        caption_text  \\\n",
              "0             a man is using a comb to cut his hair    \n",
              "1            a man on a skateboard in a parking lot    \n",
              "2  a man in a military uniform is talking to a gr...   \n",
              "3       a person laying on the floor with a blanket    \n",
              "4  a man dressed in a costume standing in front o...   \n",
              "\n",
              "                                       combined_text  \n",
              "0  nigga on ma momma youngboy be spitting real sh...  \n",
              "1  rt xxsugvngxx i ran into this holy nigga today...  \n",
              "2  everybody calling you nigger now a man in a mi...  \n",
              "3  real ass bitch give a fuck boutta nigga a pers...  \n",
              "4  nigga what a man dressed in a costume standing...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcbcc08c-04bf-4bd9-8b9f-c46975d1e0cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>caption_text</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108927368075374...</td>\n",
              "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
              "      <td>a man is using a comb to cut his hair</td>\n",
              "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/MMHS150k/img_resized/1114558534635618...</td>\n",
              "      <td>rt xxsugvngxx i ran into this holy nigga today</td>\n",
              "      <td>a man on a skateboard in a parking lot</td>\n",
              "      <td>rt xxsugvngxx i ran into this holy nigga today...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/MMHS150k/img_resized/1035252480215592...</td>\n",
              "      <td>everybody calling you nigger now</td>\n",
              "      <td>a man in a military uniform is talking to a gr...</td>\n",
              "      <td>everybody calling you nigger now a man in a mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/MMHS150k/img_resized/1106978219654303...</td>\n",
              "      <td>real ass bitch give a fuck boutta nigga</td>\n",
              "      <td>a person laying on the floor with a blanket</td>\n",
              "      <td>real ass bitch give a fuck boutta nigga a pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/MMHS150k/img_resized/1108178453910695...</td>\n",
              "      <td>nigga what</td>\n",
              "      <td>a man dressed in a costume standing in front o...</td>\n",
              "      <td>nigga what a man dressed in a costume standing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcbcc08c-04bf-4bd9-8b9f-c46975d1e0cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcbcc08c-04bf-4bd9-8b9f-c46975d1e0cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcbcc08c-04bf-4bd9-8b9f-c46975d1e0cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ec49ca3-bb20-43b4-b0b3-be8878121c1c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ec49ca3-bb20-43b4-b0b3-be8878121c1c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ec49ca3-bb20-43b4-b0b3-be8878121c1c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df_cap",
              "summary": "{\n  \"name\": \"result_df_cap\",\n  \"rows\": 74868,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74868,\n        \"samples\": [\n          \"/content/MMHS150k/img_resized/1110384608976216064.jpg\",\n          \"/content/MMHS150k/img_resized/1108130695010897921.jpg\",\n          \"/content/MMHS150k/img_resized/1110405598976360448.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66891,\n        \"samples\": [\n          \"the dyke jumped out\",\n          \"was that your best comeback you twat\",\n          \"i love letting this nigga fuck me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28734,\n        \"samples\": [\n          \"a beautiful young woman sitting on a bench \",\n          \"a person with a pair of shoes standing on a sidewalk \",\n          \"a painting of a girl with a flower in her hair \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 72413,\n        \"samples\": [\n          \"fuck my retarded existence man a dog standing on top of a grass covered field \",\n          \"obama is an absolute twat if you dont think he is as corrupt you are a fool nice banner photo a painting of a cartoon character on a wall \",\n          \"my nigger a man holding a cell phone next to another man \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_empty_captions = sum(1 for r in results if r['caption_text'] == \"\")\n",
        "print(f\"Number of empty captions: {num_empty_captions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eoHn6bwN8PJ",
        "outputId": "e6e04e82-5407-4013-9560-260a0ac030ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty captions: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM for all combined texts"
      ],
      "metadata": {
        "id": "mKHOhIWDFTmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####import necessary libraries"
      ],
      "metadata": {
        "id": "Yt0OCMUkIrgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5F6RqYmwHoO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.metrics import AUC"
      ],
      "metadata": {
        "id": "35qUsV-sFliP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load datasets and merge"
      ],
      "metadata": {
        "id": "_N060d2UI048"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OCR and caption datasets\n",
        "df_ocr = pd.read_csv(\"text_images_with_ocr_combined.csv\")\n",
        "df_caption = pd.read_csv(\"img2text_captions.csv\")\n",
        "\n",
        "# Merge\n",
        "df_all = pd.concat([df_ocr, df_caption], ignore_index=True)"
      ],
      "metadata": {
        "id": "LFylDayDH4aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Get labels"
      ],
      "metadata": {
        "id": "6TfIallZI5sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON labels\n",
        "with open(\"/content/MMHS150k/MMHS150K_GT.json\", \"r\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Extract image ID and assign labels\n",
        "df_all[\"image_id\"] = df_all[\"image_path\"].apply(lambda x: os.path.basename(x).replace(\".jpg\", \"\"))\n",
        "df_all[\"labels\"] = df_all[\"image_id\"].apply(lambda x: metadata.get(x, {}).get(\"labels\", []))"
      ],
      "metadata": {
        "id": "xYRsq9NcH_vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tokenize and Binarize"
      ],
      "metadata": {
        "id": "-p9cfZ1tJDNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out missing/empty rows\n",
        "df_all = df_all[df_all[\"combined_text\"].notnull()]\n",
        "df_all = df_all[df_all[\"labels\"].map(len) > 0]\n",
        "\n",
        "# Tokenize text\n",
        "texts = df_all[\"combined_text\"].tolist()\n",
        "labels = df_all[\"labels\"].tolist()\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "# Binarize multi-label\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(labels)"
      ],
      "metadata": {
        "id": "NQ-GnV8TIRTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train-Test split"
      ],
      "metadata": {
        "id": "gtyu7y5sJdoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train/test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "kowEwBu9IV12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Trian the LSTM model"
      ],
      "metadata": {
        "id": "374viXPbJghi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=20000, output_dim=128, input_length=100),\n",
        "    LSTM(64),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(Y.shape[1], activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, Y_train, epochs=5, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ7eLfiqIYkX",
        "outputId": "7c890cb7-abde-483e-f58f-5ddac0ad0cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.9380 - auc: 0.9033 - loss: 0.3174 - val_accuracy: 0.9232 - val_auc: 0.9346 - val_loss: 0.2713\n",
            "Epoch 2/5\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.9048 - auc: 0.9382 - loss: 0.2651 - val_accuracy: 0.9003 - val_auc: 0.9347 - val_loss: 0.2720\n",
            "Epoch 3/5\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8985 - auc: 0.9472 - loss: 0.2473 - val_accuracy: 0.8717 - val_auc: 0.9316 - val_loss: 0.2784\n",
            "Epoch 4/5\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8875 - auc: 0.9548 - loss: 0.2301 - val_accuracy: 0.8905 - val_auc: 0.9268 - val_loss: 0.2925\n",
            "Epoch 5/5\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8819 - auc: 0.9639 - loss: 0.2064 - val_accuracy: 0.8740 - val_auc: 0.9188 - val_loss: 0.3157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7adca0896350>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Evaluate"
      ],
      "metadata": {
        "id": "bnwa-PanJkR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "mOcRIiXqrAbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report, hamming_loss,\n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "Y_pred_prob = model.predict(X_test)\n",
        "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Per-class names\n",
        "target_names = list(map(str, mlb.classes_))\n",
        "\n",
        "# Print Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(Y_test, Y_pred_bin, target_names=target_names, zero_division=0))\n",
        "\n",
        "# Global metrics\n",
        "print(\"F1 Score (Micro)             :\", round(f1_score(Y_test, Y_pred, average=\"micro\"), 4))\n",
        "print(\"F1 Score (Macro)             :\", round(f1_score(Y_test, Y_pred, average=\"macro\"), 4))\n",
        "print(\"ROC AUC (Macro)              :\", round(roc_auc_score(Y_test, Y_pred_prob, average=\"macro\"), 4))\n",
        "print(\"Mean Average Precision (mAP) :\", round(average_precision_score(Y_test, Y_pred_prob, average=\"macro\"), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHiD4pjruD6k",
        "outputId": "dc2eafc4-bcd9-40c4-9ee9-beed66602f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     28265\n",
            "           1       0.50      0.32      0.39      9943\n",
            "           2       0.46      0.37      0.41      3759\n",
            "           3       0.69      0.48      0.57      2424\n",
            "           4       0.32      0.05      0.09       465\n",
            "           5       0.59      0.35      0.44      4877\n",
            "\n",
            "   micro avg       0.81      0.71      0.76     49733\n",
            "   macro avg       0.58      0.43      0.48     49733\n",
            "weighted avg       0.77      0.71      0.73     49733\n",
            " samples avg       0.86      0.78      0.78     49733\n",
            "\n",
            "F1 Score (Micro)             : 0.7603\n",
            "F1 Score (Macro)             : 0.4772\n",
            "ROC AUC (Macro)              : 0.7292\n",
            "Mean Average Precision (mAP) : 0.479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Subset Accuracy (Exact Match)\n",
        "subset_accuracy = np.all(Y_test == Y_pred, axis=1).mean()\n",
        "\n",
        "# Sample-wise Jaccard\n",
        "def jaccard_score_per_sample(y_true, y_pred):\n",
        "    jaccard_scores = []\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        intersection = np.logical_and(true, pred).sum()\n",
        "        union = np.logical_or(true, pred).sum()\n",
        "        score = intersection / union if union != 0 else 1.0\n",
        "        jaccard_scores.append(score)\n",
        "    return np.mean(jaccard_scores)\n",
        "\n",
        "Y_pred_proba = model.predict(X_test)\n",
        "Y_pred = (Y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "samplewise_jaccard = jaccard_score_per_sample(Y_test, Y_pred)\n",
        "print(f\"Subset Accuracy(Exact Match):{subset_accuracy:.4f}\")\n",
        "print(f\"Sample-wise Accuracy (Jaccard): {samplewise_jaccard:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBPsobOrz4nT",
        "outputId": "56b7bee4-cb43-48fa-ec35-da12149ed0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "Subset Accuracy(Exact Match):0.4177\n",
            "Sample-wise Accuracy (Jaccard): 0.6856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tune and Re-train"
      ],
      "metadata": {
        "id": "aJ3nm19amnvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner\n",
        "\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Hyper-model builder\n",
        "def build_lstm_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # tune embedding dim\n",
        "    model.add(Embedding(\n",
        "        input_dim=20000,\n",
        "        output_dim=hp.Int(\"embed_dim\", 64, 256, step=64),\n",
        "        input_length=100\n",
        "    ))\n",
        "\n",
        "    # tune LSTM units\n",
        "    model.add(LSTM(\n",
        "        units=hp.Int(\"lstm_units\", 32, 128, step=32),\n",
        "        return_sequences=False\n",
        "    ))\n",
        "\n",
        "    # dropout\n",
        "    model.add(Dropout(rate=hp.Float(\"dropout\", 0.0, 0.5, step=0.1)))\n",
        "\n",
        "    # tune dense layer size\n",
        "    model.add(Dense(\n",
        "        units=hp.Int(\"dense_units\", 32, 128, step=32),\n",
        "        activation=hp.Choice(\"dense_activation\", [\"relu\", \"tanh\"])\n",
        "    ))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(Y_train.shape[1], activation=\"sigmoid\"))\n",
        "\n",
        "    # optimizer + lr\n",
        "    opt_choice = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
        "    lr = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
        "    if opt_choice == \"adam\":\n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "    elif opt_choice == \"rmsprop\":\n",
        "        optimizer = RMSprop(learning_rate=lr)\n",
        "    else:\n",
        "        optimizer = SGD(learning_rate=lr, momentum=hp.Float(\"momentum\", 0.0, 0.9, step=0.1))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# set up the tuner\n",
        "tuner2 = kt.RandomSearch(\n",
        "    build_lstm_model,\n",
        "    objective=\"val_auc\",      # maximize AUC on val split\n",
        "    max_trials=12,\n",
        "    executions_per_trial=1,\n",
        "    directory=\"tuner_logs\",\n",
        "    project_name=\"lstm_model_rs\"\n",
        ")\n",
        "\n",
        "# run the search\n",
        "tuner2.search(\n",
        "    X_train, Y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# show results & grab best\n",
        "tuner2.results_summary()\n",
        "best_lstm = tuner2.get_best_models(num_models=1)[0]\n",
        "\n",
        "# further fine-tune best\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "chkpt     = ModelCheckpoint(\"best_lstm.h5\", monitor=\"val_loss\", save_best_only=True)\n",
        "\n",
        "best_lstm.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop, chkpt]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDkKkk5als_h",
        "outputId": "cc868e23-d0a7-4351-938d-5cbba3baee94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 Complete [00h 04m 03s]\n",
            "val_auc: 0.933539092540741\n",
            "\n",
            "Best val_auc So Far: 0.9347564578056335\n",
            "Total elapsed time: 00h 49m 34s\n",
            "Results summary\n",
            "Results in tuner_logs/lstm_model_rs\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_auc\", direction=\"max\")\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 192\n",
            "lstm_units: 64\n",
            "dropout: 0.0\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.004219350799274008\n",
            "momentum: 0.6000000000000001\n",
            "Score: 0.9347564578056335\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 192\n",
            "lstm_units: 64\n",
            "dropout: 0.2\n",
            "dense_units: 128\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.0027553911975914825\n",
            "Score: 0.934658408164978\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 128\n",
            "dropout: 0.1\n",
            "dense_units: 96\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.00033663431603295945\n",
            "Score: 0.9344901442527771\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 128\n",
            "lstm_units: 64\n",
            "dropout: 0.30000000000000004\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.0006034416622484507\n",
            "Score: 0.9344831109046936\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 256\n",
            "lstm_units: 64\n",
            "dropout: 0.30000000000000004\n",
            "dense_units: 32\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.0057519403847645385\n",
            "Score: 0.9344683885574341\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 128\n",
            "dropout: 0.2\n",
            "dense_units: 96\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.0012890987322014395\n",
            "momentum: 0.8\n",
            "Score: 0.9343967437744141\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 256\n",
            "lstm_units: 96\n",
            "dropout: 0.2\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.005554888538255859\n",
            "Score: 0.9341863393783569\n",
            "\n",
            "Trial 11 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 32\n",
            "dropout: 0.0\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: rmsprop\n",
            "lr: 0.00019188694664461315\n",
            "momentum: 0.30000000000000004\n",
            "Score: 0.933539092540741\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 192\n",
            "lstm_units: 128\n",
            "dropout: 0.4\n",
            "dense_units: 64\n",
            "dense_activation: relu\n",
            "optimizer: adam\n",
            "lr: 0.0052100088789352106\n",
            "momentum: 0.5\n",
            "Score: 0.9322616457939148\n",
            "\n",
            "Trial 10 summary\n",
            "Hyperparameters:\n",
            "embed_dim: 64\n",
            "lstm_units: 128\n",
            "dropout: 0.1\n",
            "dense_units: 96\n",
            "dense_activation: tanh\n",
            "optimizer: adam\n",
            "lr: 0.00892879339836686\n",
            "momentum: 0.6000000000000001\n",
            "Score: 0.9301417469978333\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3370/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9019 - auc: 0.9393 - loss: 0.2629"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - accuracy: 0.9019 - auc: 0.9393 - loss: 0.2629 - val_accuracy: 0.9215 - val_auc: 0.9341 - val_loss: 0.2750\n",
            "Epoch 2/20\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8954 - auc: 0.9451 - loss: 0.2519 - val_accuracy: 0.8880 - val_auc: 0.9297 - val_loss: 0.2791\n",
            "Epoch 3/20\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8863 - auc: 0.9499 - loss: 0.2412 - val_accuracy: 0.8854 - val_auc: 0.9292 - val_loss: 0.2869\n",
            "Epoch 4/20\n",
            "\u001b[1m3371/3371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.8783 - auc: 0.9552 - loss: 0.2296 - val_accuracy: 0.8763 - val_auc: 0.9237 - val_loss: 0.3002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799bf76182d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    hamming_loss\n",
        ")\n",
        "\n",
        "# Predict probabilities & binarize\n",
        "y_prob = best_lstm.predict(X_test)             # shape=(n_samples, n_labels)\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "# Per-class report\n",
        "target_names = [str(c) for c in range(y_pred.shape[1])]\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(\n",
        "    Y_test, y_pred,\n",
        "    target_names=target_names,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Global scalar metrics\n",
        "print(f\"Accuracy (subset-avg) : {accuracy_score(Y_test, y_pred):.4f}\")\n",
        "print(f\"F1 Score (micro)      : {f1_score(Y_test, y_pred, average='micro'):.4f}\")\n",
        "print(f\"F1 Score (macro)      : {f1_score(Y_test, y_pred, average='macro'):.4f}\")\n",
        "print(f\"Hamming Loss          : {hamming_loss(Y_test, y_pred):.4f}\")\n",
        "print(f\"ROC AUC (macro)       : {roc_auc_score(Y_test, y_prob, average='macro'):.4f}\")\n",
        "print(f\"Mean Average Precision: {average_precision_score(Y_test, y_prob, average='macro'):.4f}\")\n",
        "\n",
        "# Exact-match (subset) accuracy\n",
        "subset_acc = np.all(Y_test == y_pred, axis=1).mean()\n",
        "print(f\"Subset Accuracy       : {subset_acc:.4f}\")\n",
        "\n",
        "# Sample-wise Jaccard\n",
        "def sample_jaccard(y_true, y_pred):\n",
        "    inter = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    uni   = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (inter / (uni + 1e-7)).mean()\n",
        "\n",
        "jaccard = sample_jaccard(Y_test, y_pred)\n",
        "print(f\"Jaccard (sample-wise) : {jaccard:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnAE_JYnQUDV",
        "outputId": "097f3974-7315-4fbd-a57a-efb0e1857fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     28265\n",
            "           1       0.68      0.15      0.24      9943\n",
            "           2       0.55      0.25      0.34      3759\n",
            "           3       0.71      0.57      0.63      2424\n",
            "           4       0.00      0.00      0.00       465\n",
            "           5       0.71      0.32      0.44      4877\n",
            "\n",
            "   micro avg       0.89      0.68      0.77     49733\n",
            "   macro avg       0.60      0.38      0.44     49733\n",
            "weighted avg       0.82      0.68      0.70     49733\n",
            " samples avg       0.92      0.75      0.79     49733\n",
            "\n",
            "Accuracy (subset-avg) : 0.4565\n",
            "F1 Score (micro)      : 0.7661\n",
            "F1 Score (macro)      : 0.4375\n",
            "Hamming Loss          : 0.1140\n",
            "ROC AUC (macro)       : 0.7609\n",
            "Mean Average Precision: 0.5151\n",
            "Subset Accuracy       : 0.4565\n",
            "Jaccard (sample-wise) : 0.7053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multimodal Model (Image + Text)"
      ],
      "metadata": {
        "id": "c8L2gM8XIoT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Import Libraries"
      ],
      "metadata": {
        "id": "QzBN1HqOZC1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertConfig\n",
        "from transformers import BertModel\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "xREOjBkUOaHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch torchvision sentencepiece\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AuTqnLd3OoVc",
        "outputId": "e60f3a86-ac35-449a-aca0-50ba2c1b9453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "5b9caedaab3340b99f715cd0d82d2210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create a debug dataset"
      ],
      "metadata": {
        "id": "TLf-PZwNZKDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DO_DEBUG_WITH_SMALL_DATASET = 0\n",
        "NUM_OF_CLASSES = 6\n",
        "probabilities = [0.6, 0.3, 0.1, 0.0, 0.0, 0.0]\n",
        "mysoftmax=nn.Softmax(dim=0)\n",
        "USELOCALTOKERN=1\n",
        "#print(transformers.__version__  )\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "sDpUEaq9Oq_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Define necessary functions and classes"
      ],
      "metadata": {
        "id": "PQaPfmWeZP_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jaccard accuracy\n",
        "def compute_accuracy(taglist, predlist):\n",
        "    total_score = 0.0\n",
        "    for true, pred in zip(taglist, predlist):\n",
        "        s_true = set(true)\n",
        "        s_pred = set(pred)\n",
        "        inter = len(s_true & s_pred)\n",
        "        union = len(s_true | s_pred)\n",
        "        total_score += inter / union\n",
        "    return total_score / len(taglist)\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for text_input_ids, text_attention_mask, image_inputs, labels in test_loader:\n",
        "\n",
        "            preds0 = copy.deepcopy(labels)  # the labels is in shape as Tensor(batchsize,num_of_class)  batchsize=32,  num_of_class=6\n",
        "            # to  get （First second third） data\n",
        "            _, m1 = torch.max(preds0, dim=1)  # get max idx into m1\n",
        "            # preds0[:,m1] = -1\n",
        "            for k in range(len(m1)):\n",
        "                preds0[k, m1[k].item()] = 0\n",
        "\n",
        "            _, m2 = torch.max(preds0, dim=1)  # get the second max idx into m2\n",
        "            # preds0[:,m2] = -1\n",
        "            for k in range(len(m2)):\n",
        "                preds0[k, m2[k].item()] = 0\n",
        "\n",
        "            _, m3 = torch.max(preds0, dim=1)  # get the third max idx into m3\n",
        "            # preds0[:,m3] = -1\n",
        "            for k in range(len(m3)):\n",
        "                preds0[k, m3[k].item()] = 0\n",
        "\n",
        "            lable_Result = []\n",
        "            for k in range(len(m3)):  # for each sample in the batch\n",
        "                m = [m1[k].item(), m2[k].item(), m3[k].item()]\n",
        "                # m.sort()\n",
        "                lable_Result.append(m)  # save the sorted label—index\n",
        "\n",
        "            text_input_ids, text_attention_mask = text_input_ids.to(device), text_attention_mask.to(device)\n",
        "            image_inputs, labels = image_inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(text_input_ids, text_attention_mask, image_inputs)\n",
        "\n",
        "            # Get the predicted class by taking the argmax of the outputs\n",
        "            '''\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            _, labels = torch.max(labels, dim=1) # yg add\n",
        "            # Store the labels and predictions\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())'''\n",
        "\n",
        "            output = outputs.cpu()\n",
        "            preds0 = copy.deepcopy(output)\n",
        "            _, m1 = torch.max(preds0, dim=1)\n",
        "            for k in range(len(m1)):\n",
        "                preds0[k, m1[k].item()] = -1\n",
        "\n",
        "            _, m2 = torch.max(preds0, dim=1)\n",
        "            for k in range(len(m2)):\n",
        "                preds0[k, m2[k].item()] = -1\n",
        "\n",
        "            _, m3 = torch.max(preds0, dim=1)  # m3 = np.argmax(preds0)\n",
        "            for k in range(len(m3)):\n",
        "                preds0[k, m3[k].item()] = -1\n",
        "\n",
        "            predRes = []\n",
        "            for k in range(len(m3)):\n",
        "                m = [m1[k].item(), m2[k].item(), m3[k].item()]\n",
        "                # m.sort()\n",
        "                predRes.append(m)\n",
        "\n",
        "            # lable_Result=torch.tensor(lable_Result)\n",
        "            # predRes=torch.tensor(predRes)\n",
        "            all_labels.extend(lable_Result)\n",
        "            all_preds.extend(predRes)\n",
        "\n",
        "    all_labels = np.array([[1 if i in labels else 0 for i in range(6)] for labels in all_labels])\n",
        "    all_preds = np.array([[1 if i in preds else 0 for i in range(6)] for preds in all_preds])\n",
        "\n",
        "    # Metrices\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    return all_preds, all_labels\n",
        "\n",
        "\n",
        "\n",
        "def view_classification_results(model, test_loader, num_examples=10):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    examples_shown = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for text_input_ids, text_attention_mask, image_inputs, labels in test_loader:\n",
        "\n",
        "            text_input_ids, text_attention_mask = text_input_ids.to(device), text_attention_mask.to(device)\n",
        "            image_inputs, labels = image_inputs.to(device), labels.to(device)\n",
        "            # Forward pass through the model\n",
        "            outputs = model(text_input_ids, text_attention_mask, image_inputs)\n",
        "\n",
        "            # Get the predicted class by taking the argmax of the outputs\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Loop through the batch and print predictions along with true labels\n",
        "            for i in range(len(preds)):\n",
        "                if examples_shown >= num_examples:\n",
        "                    return  # Stop after showing the desired number of examples\n",
        "\n",
        "                # true_label = labels[i].item()  # here  labels[i] == [ 0,0.3,0.1,0,0.6,0]\n",
        "                # predicted_label = preds[i].item()\n",
        "\n",
        "                #print(\"labels={}\".format(labels[i]))\n",
        "                #print(\"preds={}\".format(outputs[i]))\n",
        "                true_labels0 = labels[i].cpu() .detach().numpy()\n",
        "                predicted_labels0 = outputs[i].cpu() .detach().numpy()    #_,=torch.max(outputs[i])\n",
        "                min_label = np.min(true_labels0)\n",
        "                min_pres_label = np.min(predicted_labels0)\n",
        "\n",
        "                true_labels=[]\n",
        "                predicted_labels=[]\n",
        "\n",
        "                # add in first three label\n",
        "                true_label= np.argmax(true_labels0)\n",
        "                true_labels.append(true_label)\n",
        "                true_labels0[true_label]=min_label\n",
        "                true_label = np.argmax(true_labels0)\n",
        "                true_labels.append(true_label)\n",
        "                true_labels0[true_label] = min_label\n",
        "                true_label = np.argmax(true_labels0)\n",
        "                true_labels.append(true_label)\n",
        "\n",
        "\n",
        "                predicted_label = np.argmax(predicted_labels0)\n",
        "                predicted_labels.append(predicted_label)\n",
        "                predicted_labels0[predicted_label]=min_pres_label\n",
        "                predicted_label = np.argmax(predicted_labels0)\n",
        "                predicted_labels.append(predicted_label)\n",
        "                predicted_labels0[predicted_label] = min_pres_label\n",
        "                predicted_label = np.argmax(predicted_labels0)\n",
        "                predicted_labels.append(predicted_label)\n",
        "\n",
        "                print(f\"Example {examples_shown + 1}:\")\n",
        "                print(f\"Predicted Label: {predicted_labels}\")\n",
        "                print(f\"True Label: {true_labels}\")\n",
        "                print(\"\")\n",
        "\n",
        "                examples_shown += 1"
      ],
      "metadata": {
        "id": "NJefSVC174AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained BERT model for text classification\n",
        "        self.text_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "        # Load pre-trained ResNet model for image classification\n",
        "        self.image_model = models.resnet18(pretrained=True)\n",
        "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 512)  # Modify final layer\n",
        "        self.image_model = self.image_model.to(device)\n",
        "\n",
        "        # Final classification layer (512 + 768 from text BERT output)\n",
        "        self.classifier = nn.Linear(512 + 768, 6).to(device)  # 6 output classes (NotHate, Racist, etc.)\n",
        "\n",
        "\n",
        "    def forward(self, text_input_ids, text_attention_mask, image_input):\n",
        "        # Forward pass through BERT for text\n",
        "        text_outputs = self.text_model(input_ids=text_input_ids, attention_mask=text_attention_mask)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "\n",
        "        # Forward pass through ResNet for image\n",
        "        image_embedding = self.image_model(image_input)\n",
        "\n",
        "        # Concatenate text and image embeddings\n",
        "        combined_embedding = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "\n",
        "        # Final classification output\n",
        "        output = self.classifier(combined_embedding)\n",
        "        output2 = mysoftmax(output)\n",
        "        return output2\n"
      ],
      "metadata": {
        "id": "PMXjsZ9g7__e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    first=1\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for text_input_ids, text_attention_mask, image_inputs, labels in val_loader:\n",
        "\n",
        "            preds0 = copy.deepcopy(labels)      # the labels is in shape as Tensor(batchsize,num_of_class)  batchsize=32,  num_of_class=6\n",
        "            # to  get （First second third） data\n",
        "            _, m1 = torch.max(preds0, dim=1)    # get max idx into m1\n",
        "            #preds0[:,m1] = -1\n",
        "            for k in range(len(m1)):\n",
        "                preds0[k,m1[k].item()] = 0\n",
        "\n",
        "            _, m2 = torch.max(preds0, dim=1)    # get the second max idx into m2\n",
        "            #preds0[:,m2] = -1\n",
        "            for k in range(len(m2)):\n",
        "                preds0[k, m2[k].item()] = 0\n",
        "\n",
        "            _, m3 = torch.max(preds0, dim=1)    # get the third max idx into m3\n",
        "            #preds0[:,m3] = -1\n",
        "            for k in range(len(m3)):\n",
        "                preds0[k, m3[k].item()] = 0\n",
        "\n",
        "            lable_Result = []\n",
        "            for k in range(len(m3)):            # for each sample in the batch\n",
        "                m=[m1[k].item(),m2[k].item(),m3[k].item()]\n",
        "                #m.sort()\n",
        "                lable_Result.append(m)          # save the sorted label—index\n",
        "\n",
        "            # Predict by model\n",
        "            text_input_ids, text_attention_mask = text_input_ids.to(device), text_attention_mask.to(device)\n",
        "            image_inputs, labels = image_inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(text_input_ids, text_attention_mask, image_inputs)\n",
        "\n",
        "            # Get the predicted class by taking the argmax of the outputs\n",
        "\n",
        "            #outputs = outputs.cpu().numpy()\n",
        "            '''\n",
        "            _,preds_idx = torch.max(outputs, dim=1)  # pred is [batchsize][1]\n",
        "            _,labels_idx = torch.max(labels,dim=1)\n",
        "            all_labels.extend(labels_idx.cpu().numpy())\n",
        "            all_preds.extend(preds_idx.cpu().numpy())'''\n",
        "\n",
        "\n",
        "            output = outputs.cpu()\n",
        "            preds0 = copy.deepcopy(output)\n",
        "            _, m1 = torch.max(preds0, dim=1)\n",
        "            for k in range(len(m1)):\n",
        "                preds0[k, m1[k].item()] = -1\n",
        "\n",
        "            _, m2 = torch.max(preds0, dim=1)\n",
        "            for k in range(len(m2)):\n",
        "                preds0[k, m2[k].item()] = -1\n",
        "\n",
        "            _, m3 = torch.max(preds0, dim=1)    #m3 = np.argmax(preds0)\n",
        "            for k in range(len(m3)):\n",
        "                preds0[k, m3[k].item()] = -1\n",
        "\n",
        "            predRes = []\n",
        "            for k in range(len(m3)):\n",
        "                m=[m1[k].item(),m2[k].item(),m3[k].item()]\n",
        "                #m.sort()\n",
        "                predRes.append(m)\n",
        "\n",
        "            #lable_Result=torch.tensor(lable_Result)\n",
        "            #predRes=torch.tensor(predRes)\n",
        "            all_labels.extend(lable_Result)\n",
        "            all_preds.extend(predRes)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    #accuracy = accuracy_score(all_labels, all_preds)\n",
        "    accuracy = compute_accuracy(all_labels, all_preds)\n",
        "    return accuracy\n",
        "# Training loop with validation\n",
        "def train_and_validate(model, train_loader, val_loader, num_epochs=5):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        first=1\n",
        "        for text_input_ids, text_attention_mask, image_inputs, labels in train_loader:\n",
        "\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "            # labels=labels.softmax(dim=1)\n",
        "\n",
        "            text_input_ids, text_attention_mask = text_input_ids.to(device), text_attention_mask.to(device)\n",
        "            image_inputs, labels = image_inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(text_input_ids, text_attention_mask, image_inputs)\n",
        "\n",
        "            if first==1:\n",
        "                #print(\"epoch ={},output={} \\nlabels={}\".format(epoch,outputs,labels))\n",
        "                first = 0\n",
        "\n",
        "            loss = criterion(outputs, labels)  # Compute the loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # After each epoch, validate the model\n",
        "        val_accuracy = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        #print(\"GPU usage after epoch:\")\n",
        "        #!nvidia-smi\n"
      ],
      "metadata": {
        "id": "0BeEwUnA8DaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, tweet_data, tokenizer, image_transform):\n",
        "        self.tweet_data = tweet_data  # List of dictionaries containing tweet information\n",
        "        self.tokenizer = tokenizer    # BERT tokenizer for processing tweet text\n",
        "        self.image_transform = image_transform  # Transformations for image preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweet_data)\n",
        "\n",
        "    def __getitem__(self, idx):                 # Get tweet data at the given index\n",
        "        tweet = self.tweet_data[idx]            # Process the text using the BERT tokenizer\n",
        "        text = tweet['text']\n",
        "        text_encoding = self.tokenizer(\n",
        "            text, padding='max_length', truncation=True, max_length=128, return_tensors='pt'\n",
        "        )\n",
        "        text_input_ids = text_encoding['input_ids'].squeeze(0)  # Tokenized text input\n",
        "        text_attention_mask = text_encoding['attention_mask'].squeeze(0)  # Attention mask\n",
        "\n",
        "        # Process the image\n",
        "        image = Image.open(tweet['img_path']).convert('RGB')  # Open image as a PIL Image\n",
        "        image = self.image_transform(image)  # Apply transformations to convert to tensor\n",
        "        # Get the label\n",
        "        #label = max(set(tweet['labels']), key=tweet['labels'].count)  # Majority vote\n",
        "        labels = tweet['labels']\n",
        "        labels_out=[0.0] * NUM_OF_CLASSES\n",
        "        '''  a method to count labels\n",
        "        k=0\n",
        "        for l in labels:\n",
        "            if labels_out[l]==0.0:\n",
        "                labels_out[l]=probabilities[k]\n",
        "                k+=1'''\n",
        "        for idx in labels:      # another method to count the labels\n",
        "            labels_out[idx]+=1.0/3\n",
        "        label = np.array(labels_out)\n",
        "        label = mysoftmax(torch.tensor(label))\n",
        "        return text_input_ids, text_attention_mask, image, label #  torch.tensor(label)\n"
      ],
      "metadata": {
        "id": "yQ7k8bKN8HXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_device(batch, device):\n",
        "    text_input_ids, text_attention_mask, image_inputs, labels = batch\n",
        "    text_input_ids = text_input_ids.to(device)\n",
        "    text_attention_mask = text_attention_mask.to(device)\n",
        "    image_inputs = image_inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    return text_input_ids, text_attention_mask, image_inputs, labels"
      ],
      "metadata": {
        "id": "644aMuqd8JV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Preprocess data and create data loaders"
      ],
      "metadata": {
        "id": "k0C6k5JdZppT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load json file\n",
        "json_path = '/content/MMHS150k/MMHS150K_GT.json'\n",
        "with open(json_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "image_folder = '/content/MMHS150k/img_resized/'\n",
        "\n",
        "# Construct the empty list for later data storage\n",
        "tweet_data = []\n",
        "# Extract tweet text, labels, and image paths from the JSON data\n",
        "for tweet_id, tweet_info in data.items():\n",
        "    img_path = os.path.join(image_folder, f\"{tweet_id}.jpg\")\n",
        "    tweet_text = tweet_info['tweet_text']\n",
        "    labels = tweet_info['labels']\n",
        "    labels_str = tweet_info['labels_str']\n",
        "\n",
        "    # Append the relevant information in a dictionary for each tweet\n",
        "    tweet_data.append({\n",
        "        'tweet_id': tweet_id,\n",
        "        'img_path': img_path,\n",
        "        'text': tweet_text,\n",
        "        'labels': labels,\n",
        "        'labels_str': labels_str\n",
        "    })\n",
        "\n",
        "# Inspect the data\n",
        "print(f\"Number of tweets processed: {len(tweet_data)}\")\n",
        "print(tweet_data[0])\n",
        "\n",
        "# Load the tweet IDs for each split\n",
        "with open('MMHS150k/splits/train_ids.txt', 'r') as f:\n",
        "    train_ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "with open('MMHS150k/splits/val_ids.txt', 'r') as f:\n",
        "    val_ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "with open('MMHS150k/splits/test_ids.txt', 'r') as f:\n",
        "    test_ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "if DO_DEBUG_WITH_SMALL_DATASET == 1:\n",
        "    train_ids = train_ids[:64]\n",
        "    val_ids = val_ids[:32]\n",
        "    test_ids = test_ids[:32]\n",
        "    print(\"Number of training ids:\", len(train_ids))\n",
        "    print(\"Number of validation ids:\", len(val_ids))\n",
        "\n",
        "# Split the tweet_data list into train, val, and test based on these IDs\n",
        "train_data = [tweet for tweet in tweet_data if tweet['tweet_id'] in train_ids]\n",
        "val_data = [tweet for tweet in tweet_data if tweet['tweet_id'] in val_ids]\n",
        "test_data = [tweet for tweet in tweet_data if tweet['tweet_id'] in test_ids]\n",
        "\n",
        "# Verify the sizes of the splits\n",
        "print(f\"Training samples: {len(train_data)}, Validation samples: {len(val_data)}, Test samples: {len(test_data)}\")\n",
        "\n",
        "# Define the image transformations (resize to 224x224 and normalize)\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "if tokenizer:\n",
        "    print('tokenizer init successfully!')\n",
        "    print(tokenizer)\n",
        "else:\n",
        "    print('tokenizer init failure!')\n",
        "    assert False\n",
        "\n",
        "# Create Dataset objects for each split\n",
        "train_dataset = TweetDataset(train_data, tokenizer, image_transform)\n",
        "val_dataset = TweetDataset(val_data, tokenizer, image_transform)\n",
        "test_dataset = TweetDataset(test_data, tokenizer, image_transform)\n",
        "\n",
        "num_workers = 10\n",
        "batch_size = 32\n",
        "if DO_DEBUG_WITH_SMALL_DATASET == 1:\n",
        "    num_workers = 1\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "2198b5c5c2b345498d4549b18bac8b6a",
            "3d6b29e6e3f04012bd3c2d34e441302d",
            "4e1e9308964941d581057af5a70835f6",
            "991844232f8442e99a14e46dd61d3822",
            "b5b3390d391849fb85758cdf72bd9749",
            "c5185b24e1234cab8cf91d6b7fa864eb",
            "f9d11f4215a847efac00c0045a6e0440",
            "e867fd16aa8544ea867f1c4aae40bad7",
            "6e0bfb4e06dd4cba8ff041c745eb570e",
            "430df64c3d7a44bb84412439846062fb",
            "a3f01634a6654572a0673eb8c34f18d3",
            "a02a0644fd5d4e62a4a15645dd3e32c8",
            "d10e395050704ec591143500de6eed72",
            "18f47141d158492eb0798beb1db25e5e",
            "dc12e7f1fe63444c9712dbc9bf7a28d1",
            "aad5c4fffae041aea58e0be154e594d9",
            "d11209b79baf45989d5c33459a546bbf",
            "5f096c4390bc4bb790e15831a5cdfefd",
            "a4e84ff9c4274ecfa9f824df16064916",
            "0544efcf9997453690b65c62d84cb023",
            "afafa8dc8b89492d8de254129be9cf87",
            "0fab9d1b45064ae2a295e32b68a836eb",
            "8d39517b1d7540848d78264115b1a2a8",
            "21070b999987427192adc27b5aef4051",
            "9bdaeed4d96644da923c7f06e989f36e",
            "beb5a63a16454465a494525a6082a2ce",
            "2d0adc2892464cef9150fed62169d047",
            "2b27cd0202044f2282160aeac1994557",
            "f3ee243c341f46e2aead8cbafdc968fc",
            "2005ae833d1c469a85da7e3b09467a5b",
            "be5fbae28e944bedb2b129a4369e728f",
            "47ea697a2b204c33a63daf7c2fb73e06",
            "c22f5dd016e94e919b9b4336f08272bf",
            "3660602b41b643e49e1266023f5aad24",
            "e76fedd66a1741de82f9fe64a6640e3d",
            "5335c3cf3f4441ca81d3f907d279298f",
            "454e8dd3bf10407280091c02797229fe",
            "4771ec0dfd524bfda065279e781706f0",
            "38b8f9626ebe4ff3b63cf8797daeb1f9",
            "fc1d568aaccc452689704a4e13886098",
            "c71f75cb0cbc49c1b11525575d0ff78c",
            "f730a4ab6fda4f6a84715aed8421d8fa",
            "0d65ac8a65c44578af6ea7a57c57c4b1",
            "b498a3d77c874371a52d4de963b696ca"
          ]
        },
        "id": "7U8gVwD7UufT",
        "outputId": "1da9ff95-b1fa-44c6-e74c-76353c6d463f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets processed: 149823\n",
            "{'tweet_id': '1114679353714016256', 'img_path': '/content/MMHS150k/img_resized/1114679353714016256.jpg', 'text': '@FriskDontMiss Nigga https://t.co/cAsaLWEpue', 'labels': [4, 1, 3], 'labels_str': ['Religion', 'Racist', 'Homophobe']}\n",
            "Training samples: 134823, Validation samples: 5000, Test samples: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2198b5c5c2b345498d4549b18bac8b6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a02a0644fd5d4e62a4a15645dd3e32c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d39517b1d7540848d78264115b1a2a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3660602b41b643e49e1266023f5aad24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer init successfully!\n",
            "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train and validate the model"
      ],
      "metadata": {
        "id": "1VAoXCBHZ3TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = MultimodalModel().to(device)\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Call the training function with timing\n",
        "num_epochs = 10\n",
        "if DO_DEBUG_WITH_SMALL_DATASET == 1:\n",
        "    num_epochs = 1\n",
        "\n",
        "train_and_validate(model, train_loader, val_loader, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "8c8ed47464c240fdba27ccd349abd97c",
            "73c75c6a907f4b2b8cdbbd78d17d9fae",
            "e6eb5222dbef44bd93680b7d2dc6b701",
            "76502d0b99104bdda2ae56d45d4156d5",
            "5ff9044a46de444ea4e87d59d6912675",
            "09792d75690b43e2989bc566ffcc63c6",
            "57460589b92348e9b49a619d8ad78a0f",
            "2ed70816e1984d28b98127bff989d909",
            "5187192347604c5e8ed5bc4f41866921",
            "7a651ad894e548978f186fd2a009a226",
            "93b0ca00a61c412899dd9f573fbaa6db"
          ]
        },
        "id": "RYqnDnPjVDji",
        "outputId": "302de63d-480f-41a2-df4d-d26292c7c302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c8ed47464c240fdba27ccd349abd97c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 227MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 7547.5341, Validation Accuracy: 0.3548\n",
            "Epoch [2/10], Loss: 7547.3430, Validation Accuracy: 0.3578\n",
            "Epoch [3/10], Loss: 7546.0767, Validation Accuracy: 0.3419\n",
            "Epoch [4/10], Loss: 7544.3031, Validation Accuracy: 0.3332\n",
            "Epoch [5/10], Loss: 7541.8144, Validation Accuracy: 0.3352\n",
            "Epoch [6/10], Loss: 7538.9211, Validation Accuracy: 0.3479\n",
            "Epoch [7/10], Loss: 7536.1234, Validation Accuracy: 0.3375\n",
            "Epoch [8/10], Loss: 7533.5703, Validation Accuracy: 0.3162\n",
            "Epoch [9/10], Loss: 7531.3203, Validation Accuracy: 0.3001\n",
            "Epoch [10/10], Loss: 7529.6641, Validation Accuracy: 0.3356\n",
            "Finished 10 epochs in 116.3 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test the model and view sample results"
      ],
      "metadata": {
        "id": "JQX1PxFBZ8cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the test function after training\n",
        "y_pred, y_true  = test_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gsn7-Vh-v26",
        "outputId": "c0312d3a-12de-4ad1-94e6-e2c539bf5c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5179\n",
            "Recall: 0.5313\n",
            "F1 Score: 0.4026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Jaccard Accuracy\n",
        "\n",
        "def multilabel_accuracy(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred).sum(axis=1)\n",
        "    union = np.logical_or(y_true, y_pred).sum(axis=1)\n",
        "    return (intersection / (union + 1e-7)).mean()\n",
        "\n",
        "sample_accuracy = multilabel_accuracy(y_true, y_pred)\n",
        "print(\"Sample-wise Accuracy (Jaccard):\", sample_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sbqFmRf616e",
        "outputId": "53a9e66b-5a90-43d5-fc27-71900d7f9798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample-wise Accuracy (Jaccard): 0.32822999219681687\n"
          ]
        }
      ]
    }
  ]
}